{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "616929ea",
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "execution": {
     "iopub.execute_input": "2024-03-11T06:59:59.791519Z",
     "iopub.status.busy": "2024-03-11T06:59:59.791220Z",
     "iopub.status.idle": "2024-03-11T07:00:01.090873Z",
     "shell.execute_reply": "2024-03-11T07:00:01.089783Z"
    },
    "papermill": {
     "duration": 1.30718,
     "end_time": "2024-03-11T07:00:01.093220",
     "exception": false,
     "start_time": "2024-03-11T06:59:59.786040",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/kaggle/input/cse447-models/model.safetensors\n"
     ]
    }
   ],
   "source": [
    "# This Python 3 environment comes with many helpful analytics libraries installed\n",
    "# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n",
    "# For example, here's several helpful packages to load\n",
    "\n",
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "\n",
    "# Input data files are available in the read-only \"../input/\" directory\n",
    "# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n",
    "\n",
    "import os\n",
    "for dirname, _, filenames in os.walk('/kaggle/input'):\n",
    "    for filename in filenames:\n",
    "        print(os.path.join(dirname, filename))\n",
    "\n",
    "# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n",
    "# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "132446c5",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-03-11T07:00:01.103224Z",
     "iopub.status.busy": "2024-03-11T07:00:01.102868Z",
     "iopub.status.idle": "2024-03-11T07:00:04.181027Z",
     "shell.execute_reply": "2024-03-11T07:00:04.180082Z"
    },
    "papermill": {
     "duration": 3.085689,
     "end_time": "2024-03-11T07:00:04.183424",
     "exception": false,
     "start_time": "2024-03-11T07:00:01.097735",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cloning into 'CSE447_Project'...\r\n",
      "remote: Enumerating objects: 371, done.\u001b[K\r\n",
      "remote: Counting objects: 100% (110/110), done.\u001b[K\r\n",
      "remote: Compressing objects: 100% (71/71), done.\u001b[K\r\n",
      "remote: Total 371 (delta 64), reused 72 (delta 37), pack-reused 261\u001b[K\r\n",
      "Receiving objects: 100% (371/371), 11.20 MiB | 15.43 MiB/s, done.\r\n",
      "Resolving deltas: 100% (210/210), done.\r\n"
     ]
    }
   ],
   "source": [
    "!git clone https://github.com/PopoDev/CSE447_Project.git"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2930b270",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-03-11T07:00:04.197442Z",
     "iopub.status.busy": "2024-03-11T07:00:04.197108Z",
     "iopub.status.idle": "2024-03-11T07:00:05.225605Z",
     "shell.execute_reply": "2024-03-11T07:00:05.224526Z"
    },
    "papermill": {
     "duration": 1.037775,
     "end_time": "2024-03-11T07:00:05.228273",
     "exception": false,
     "start_time": "2024-03-11T07:00:04.190498",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[0m\u001b[01;34mCSE447_Project\u001b[0m/  __notebook__.ipynb\r\n"
     ]
    }
   ],
   "source": [
    "ls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "013a9212",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-03-11T07:00:05.241698Z",
     "iopub.status.busy": "2024-03-11T07:00:05.241328Z",
     "iopub.status.idle": "2024-03-11T07:00:05.248309Z",
     "shell.execute_reply": "2024-03-11T07:00:05.247268Z"
    },
    "papermill": {
     "duration": 0.016291,
     "end_time": "2024-03-11T07:00:05.250596",
     "exception": false,
     "start_time": "2024-03-11T07:00:05.234305",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/kaggle/working/CSE447_Project\n"
     ]
    }
   ],
   "source": [
    "cd CSE447_Project/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "db21df8a",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-03-11T07:00:05.263195Z",
     "iopub.status.busy": "2024-03-11T07:00:05.262929Z",
     "iopub.status.idle": "2024-03-11T07:00:06.440189Z",
     "shell.execute_reply": "2024-03-11T07:00:06.439252Z"
    },
    "papermill": {
     "duration": 1.186158,
     "end_time": "2024-03-11T07:00:06.442546",
     "exception": false,
     "start_time": "2024-03-11T07:00:05.256388",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Already up to date.\r\n"
     ]
    }
   ],
   "source": [
    "!git pull"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "136c99b9",
   "metadata": {
    "papermill": {
     "duration": 0.005114,
     "end_time": "2024-03-11T07:00:06.452923",
     "exception": false,
     "start_time": "2024-03-11T07:00:06.447809",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Student"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "037891a8",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-03-11T07:00:06.464626Z",
     "iopub.status.busy": "2024-03-11T07:00:06.464330Z",
     "iopub.status.idle": "2024-03-11T07:00:06.470435Z",
     "shell.execute_reply": "2024-03-11T07:00:06.469587Z"
    },
    "papermill": {
     "duration": 0.014609,
     "end_time": "2024-03-11T07:00:06.472616",
     "exception": false,
     "start_time": "2024-03-11T07:00:06.458007",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/kaggle/working/CSE447_Project/Student\n"
     ]
    }
   ],
   "source": [
    "cd /kaggle/working/CSE447_Project/Student"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "8e9014ff",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-03-11T07:00:06.484928Z",
     "iopub.status.busy": "2024-03-11T07:00:06.484163Z",
     "iopub.status.idle": "2024-03-11T07:00:07.480326Z",
     "shell.execute_reply": "2024-03-11T07:00:07.479056Z"
    },
    "papermill": {
     "duration": 1.004948,
     "end_time": "2024-03-11T07:00:07.482996",
     "exception": false,
     "start_time": "2024-03-11T07:00:06.478048",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "arguments.py  \u001b[0m\u001b[01;34mdataloader\u001b[0m/  requirements.txt  run_sbert.py  \u001b[01;34mutils\u001b[0m/\r\n",
      "\u001b[01;34mdata\u001b[0m/         \u001b[01;34mmodel\u001b[0m/       run.py            train.py\r\n"
     ]
    }
   ],
   "source": [
    "ls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "91d3d70f",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-03-11T07:00:07.496369Z",
     "iopub.status.busy": "2024-03-11T07:00:07.496043Z",
     "iopub.status.idle": "2024-03-11T07:00:23.895238Z",
     "shell.execute_reply": "2024-03-11T07:00:23.894230Z"
    },
    "papermill": {
     "duration": 16.408569,
     "end_time": "2024-03-11T07:00:23.897599",
     "exception": false,
     "start_time": "2024-03-11T07:00:07.489030",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting sentence-transformers (from -r requirements.txt (line 1))\r\n",
      "  Downloading sentence_transformers-2.5.1-py3-none-any.whl.metadata (11 kB)\r\n",
      "Collecting evaluate (from -r requirements.txt (line 2))\r\n",
      "  Downloading evaluate-0.4.1-py3-none-any.whl.metadata (9.4 kB)\r\n",
      "Requirement already satisfied: transformers<5.0.0,>=4.32.0 in /opt/conda/lib/python3.10/site-packages (from sentence-transformers->-r requirements.txt (line 1)) (4.37.0)\r\n",
      "Requirement already satisfied: tqdm in /opt/conda/lib/python3.10/site-packages (from sentence-transformers->-r requirements.txt (line 1)) (4.66.1)\r\n",
      "Requirement already satisfied: torch>=1.11.0 in /opt/conda/lib/python3.10/site-packages (from sentence-transformers->-r requirements.txt (line 1)) (2.1.2)\r\n",
      "Requirement already satisfied: numpy in /opt/conda/lib/python3.10/site-packages (from sentence-transformers->-r requirements.txt (line 1)) (1.24.4)\r\n",
      "Requirement already satisfied: scikit-learn in /opt/conda/lib/python3.10/site-packages (from sentence-transformers->-r requirements.txt (line 1)) (1.2.2)\r\n",
      "Requirement already satisfied: scipy in /opt/conda/lib/python3.10/site-packages (from sentence-transformers->-r requirements.txt (line 1)) (1.11.4)\r\n",
      "Requirement already satisfied: huggingface-hub>=0.15.1 in /opt/conda/lib/python3.10/site-packages (from sentence-transformers->-r requirements.txt (line 1)) (0.20.3)\r\n",
      "Requirement already satisfied: Pillow in /opt/conda/lib/python3.10/site-packages (from sentence-transformers->-r requirements.txt (line 1)) (9.5.0)\r\n",
      "Requirement already satisfied: datasets>=2.0.0 in /opt/conda/lib/python3.10/site-packages (from evaluate->-r requirements.txt (line 2)) (2.1.0)\r\n",
      "Requirement already satisfied: dill in /opt/conda/lib/python3.10/site-packages (from evaluate->-r requirements.txt (line 2)) (0.3.7)\r\n",
      "Requirement already satisfied: pandas in /opt/conda/lib/python3.10/site-packages (from evaluate->-r requirements.txt (line 2)) (2.1.4)\r\n",
      "Requirement already satisfied: requests>=2.19.0 in /opt/conda/lib/python3.10/site-packages (from evaluate->-r requirements.txt (line 2)) (2.31.0)\r\n",
      "Requirement already satisfied: xxhash in /opt/conda/lib/python3.10/site-packages (from evaluate->-r requirements.txt (line 2)) (3.4.1)\r\n",
      "Requirement already satisfied: multiprocess in /opt/conda/lib/python3.10/site-packages (from evaluate->-r requirements.txt (line 2)) (0.70.15)\r\n",
      "Requirement already satisfied: fsspec>=2021.05.0 in /opt/conda/lib/python3.10/site-packages (from fsspec[http]>=2021.05.0->evaluate->-r requirements.txt (line 2)) (2023.12.2)\r\n",
      "Requirement already satisfied: packaging in /opt/conda/lib/python3.10/site-packages (from evaluate->-r requirements.txt (line 2)) (21.3)\r\n",
      "Requirement already satisfied: responses<0.19 in /opt/conda/lib/python3.10/site-packages (from evaluate->-r requirements.txt (line 2)) (0.18.0)\r\n",
      "Requirement already satisfied: pyarrow>=5.0.0 in /opt/conda/lib/python3.10/site-packages (from datasets>=2.0.0->evaluate->-r requirements.txt (line 2)) (11.0.0)\r\n",
      "Requirement already satisfied: aiohttp in /opt/conda/lib/python3.10/site-packages (from datasets>=2.0.0->evaluate->-r requirements.txt (line 2)) (3.9.1)\r\n",
      "Requirement already satisfied: filelock in /opt/conda/lib/python3.10/site-packages (from huggingface-hub>=0.15.1->sentence-transformers->-r requirements.txt (line 1)) (3.13.1)\r\n",
      "Requirement already satisfied: pyyaml>=5.1 in /opt/conda/lib/python3.10/site-packages (from huggingface-hub>=0.15.1->sentence-transformers->-r requirements.txt (line 1)) (6.0.1)\r\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /opt/conda/lib/python3.10/site-packages (from huggingface-hub>=0.15.1->sentence-transformers->-r requirements.txt (line 1)) (4.9.0)\r\n",
      "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /opt/conda/lib/python3.10/site-packages (from packaging->evaluate->-r requirements.txt (line 2)) (3.1.1)\r\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.10/site-packages (from requests>=2.19.0->evaluate->-r requirements.txt (line 2)) (3.3.2)\r\n",
      "Requirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.10/site-packages (from requests>=2.19.0->evaluate->-r requirements.txt (line 2)) (3.6)\r\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /opt/conda/lib/python3.10/site-packages (from requests>=2.19.0->evaluate->-r requirements.txt (line 2)) (1.26.18)\r\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.10/site-packages (from requests>=2.19.0->evaluate->-r requirements.txt (line 2)) (2023.11.17)\r\n",
      "Requirement already satisfied: sympy in /opt/conda/lib/python3.10/site-packages (from torch>=1.11.0->sentence-transformers->-r requirements.txt (line 1)) (1.12)\r\n",
      "Requirement already satisfied: networkx in /opt/conda/lib/python3.10/site-packages (from torch>=1.11.0->sentence-transformers->-r requirements.txt (line 1)) (3.2.1)\r\n",
      "Requirement already satisfied: jinja2 in /opt/conda/lib/python3.10/site-packages (from torch>=1.11.0->sentence-transformers->-r requirements.txt (line 1)) (3.1.2)\r\n",
      "Requirement already satisfied: regex!=2019.12.17 in /opt/conda/lib/python3.10/site-packages (from transformers<5.0.0,>=4.32.0->sentence-transformers->-r requirements.txt (line 1)) (2023.12.25)\r\n",
      "Requirement already satisfied: tokenizers<0.19,>=0.14 in /opt/conda/lib/python3.10/site-packages (from transformers<5.0.0,>=4.32.0->sentence-transformers->-r requirements.txt (line 1)) (0.15.1)\r\n",
      "Requirement already satisfied: safetensors>=0.3.1 in /opt/conda/lib/python3.10/site-packages (from transformers<5.0.0,>=4.32.0->sentence-transformers->-r requirements.txt (line 1)) (0.4.2)\r\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /opt/conda/lib/python3.10/site-packages (from pandas->evaluate->-r requirements.txt (line 2)) (2.8.2)\r\n",
      "Requirement already satisfied: pytz>=2020.1 in /opt/conda/lib/python3.10/site-packages (from pandas->evaluate->-r requirements.txt (line 2)) (2023.3.post1)\r\n",
      "Requirement already satisfied: tzdata>=2022.1 in /opt/conda/lib/python3.10/site-packages (from pandas->evaluate->-r requirements.txt (line 2)) (2023.4)\r\n",
      "Requirement already satisfied: joblib>=1.1.1 in /opt/conda/lib/python3.10/site-packages (from scikit-learn->sentence-transformers->-r requirements.txt (line 1)) (1.3.2)\r\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in /opt/conda/lib/python3.10/site-packages (from scikit-learn->sentence-transformers->-r requirements.txt (line 1)) (3.2.0)\r\n",
      "Requirement already satisfied: attrs>=17.3.0 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets>=2.0.0->evaluate->-r requirements.txt (line 2)) (23.2.0)\r\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets>=2.0.0->evaluate->-r requirements.txt (line 2)) (6.0.4)\r\n",
      "Requirement already satisfied: yarl<2.0,>=1.0 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets>=2.0.0->evaluate->-r requirements.txt (line 2)) (1.9.3)\r\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets>=2.0.0->evaluate->-r requirements.txt (line 2)) (1.4.1)\r\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets>=2.0.0->evaluate->-r requirements.txt (line 2)) (1.3.1)\r\n",
      "Requirement already satisfied: async-timeout<5.0,>=4.0 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets>=2.0.0->evaluate->-r requirements.txt (line 2)) (4.0.3)\r\n",
      "Requirement already satisfied: six>=1.5 in /opt/conda/lib/python3.10/site-packages (from python-dateutil>=2.8.2->pandas->evaluate->-r requirements.txt (line 2)) (1.16.0)\r\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /opt/conda/lib/python3.10/site-packages (from jinja2->torch>=1.11.0->sentence-transformers->-r requirements.txt (line 1)) (2.1.3)\r\n",
      "Requirement already satisfied: mpmath>=0.19 in /opt/conda/lib/python3.10/site-packages (from sympy->torch>=1.11.0->sentence-transformers->-r requirements.txt (line 1)) (1.3.0)\r\n",
      "Downloading sentence_transformers-2.5.1-py3-none-any.whl (156 kB)\r\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m156.5/156.5 kB\u001b[0m \u001b[31m1.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25hDownloading evaluate-0.4.1-py3-none-any.whl (84 kB)\r\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m84.1/84.1 kB\u001b[0m \u001b[31m4.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25hInstalling collected packages: sentence-transformers, evaluate\r\n",
      "Successfully installed evaluate-0.4.1 sentence-transformers-2.5.1\r\n"
     ]
    }
   ],
   "source": [
    "!pip install -r requirements.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "7aee1e47",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-03-11T07:00:23.914054Z",
     "iopub.status.busy": "2024-03-11T07:00:23.913340Z",
     "iopub.status.idle": "2024-03-11T07:00:31.488529Z",
     "shell.execute_reply": "2024-03-11T07:00:31.487368Z"
    },
    "papermill": {
     "duration": 7.585893,
     "end_time": "2024-03-11T07:00:31.490908",
     "exception": false,
     "start_time": "2024-03-11T07:00:23.905015",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mon Mar 11 07:00:31 2024       \r\n",
      "+---------------------------------------------------------------------------------------+\r\n",
      "| NVIDIA-SMI 535.129.03             Driver Version: 535.129.03   CUDA Version: 12.2     |\r\n",
      "|-----------------------------------------+----------------------+----------------------+\r\n",
      "| GPU  Name                 Persistence-M | Bus-Id        Disp.A | Volatile Uncorr. ECC |\r\n",
      "| Fan  Temp   Perf          Pwr:Usage/Cap |         Memory-Usage | GPU-Util  Compute M. |\r\n",
      "|                                         |                      |               MIG M. |\r\n",
      "|=========================================+======================+======================|\r\n",
      "|   0  Tesla T4                       Off | 00000000:00:04.0 Off |                    0 |\r\n",
      "| N/A   39C    P8               9W /  70W |      0MiB / 15360MiB |      0%      Default |\r\n",
      "|                                         |                      |                  N/A |\r\n",
      "+-----------------------------------------+----------------------+----------------------+\r\n",
      "|   1  Tesla T4                       Off | 00000000:00:05.0 Off |                    0 |\r\n",
      "| N/A   40C    P8               9W /  70W |      0MiB / 15360MiB |      0%      Default |\r\n",
      "|                                         |                      |                  N/A |\r\n",
      "+-----------------------------------------+----------------------+----------------------+\r\n",
      "                                                                                         \r\n",
      "+---------------------------------------------------------------------------------------+\r\n",
      "| Processes:                                                                            |\r\n",
      "|  GPU   GI   CI        PID   Type   Process name                            GPU Memory |\r\n",
      "|        ID   ID                                                             Usage      |\r\n",
      "|=======================================================================================|\r\n",
      "|  No running processes found                                                           |\r\n",
      "+---------------------------------------------------------------------------------------+\r\n"
     ]
    }
   ],
   "source": [
    "import gc\n",
    "import torch\n",
    "\n",
    "model = None\n",
    "gc.collect()\n",
    "torch.cuda.empty_cache()\n",
    "!nvidia-smi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "d31fbfb9",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-03-11T07:00:31.507956Z",
     "iopub.status.busy": "2024-03-11T07:00:31.507282Z",
     "iopub.status.idle": "2024-03-11T07:02:25.940217Z",
     "shell.execute_reply": "2024-03-11T07:02:25.939030Z"
    },
    "papermill": {
     "duration": 114.443929,
     "end_time": "2024-03-11T07:02:25.942512",
     "exception": false,
     "start_time": "2024-03-11T07:00:31.498583",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-03-11 07:00:42.170028: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:9261] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\r\n",
      "2024-03-11 07:00:42.170127: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:607] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\r\n",
      "2024-03-11 07:00:42.512441: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1515] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\r\n",
      "tokenizer_config.json: 100%|█████████████████| 25.0/25.0 [00:00<00:00, 93.8kB/s]\r\n",
      "config.json: 100%|█████████████████████████████| 481/481 [00:00<00:00, 2.17MB/s]\r\n",
      "vocab.json: 100%|████████████████████████████| 899k/899k [00:00<00:00, 8.98MB/s]\r\n",
      "merges.txt: 100%|████████████████████████████| 456k/456k [00:00<00:00, 9.94MB/s]\r\n",
      "tokenizer.json: 100%|██████████████████████| 1.36M/1.36M [00:00<00:00, 26.8MB/s]\r\n",
      "model.safetensors: 100%|██████████████████████| 499M/499M [00:02<00:00, 194MB/s]\r\n",
      "Some weights of RobertaForMultipleChoice were not initialized from the model checkpoint at FacebookAI/roberta-base and are newly initialized: ['classifier.bias', 'classifier.weight', 'roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\r\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\r\n",
      "<bound method Module.parameters of RobertaForMultipleChoice(\r\n",
      "  (roberta): RobertaModel(\r\n",
      "    (embeddings): RobertaEmbeddings(\r\n",
      "      (word_embeddings): Embedding(50265, 768, padding_idx=1)\r\n",
      "      (position_embeddings): Embedding(514, 768, padding_idx=1)\r\n",
      "      (token_type_embeddings): Embedding(1, 768)\r\n",
      "      (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\r\n",
      "      (dropout): Dropout(p=0.1, inplace=False)\r\n",
      "    )\r\n",
      "    (encoder): RobertaEncoder(\r\n",
      "      (layer): ModuleList(\r\n",
      "        (0-11): 12 x RobertaLayer(\r\n",
      "          (attention): RobertaAttention(\r\n",
      "            (self): RobertaSelfAttention(\r\n",
      "              (query): Linear(in_features=768, out_features=768, bias=True)\r\n",
      "              (key): Linear(in_features=768, out_features=768, bias=True)\r\n",
      "              (value): Linear(in_features=768, out_features=768, bias=True)\r\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\r\n",
      "            )\r\n",
      "            (output): RobertaSelfOutput(\r\n",
      "              (dense): Linear(in_features=768, out_features=768, bias=True)\r\n",
      "              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\r\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\r\n",
      "            )\r\n",
      "          )\r\n",
      "          (intermediate): RobertaIntermediate(\r\n",
      "            (dense): Linear(in_features=768, out_features=3072, bias=True)\r\n",
      "            (intermediate_act_fn): GELUActivation()\r\n",
      "          )\r\n",
      "          (output): RobertaOutput(\r\n",
      "            (dense): Linear(in_features=3072, out_features=768, bias=True)\r\n",
      "            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\r\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\r\n",
      "          )\r\n",
      "        )\r\n",
      "      )\r\n",
      "    )\r\n",
      "    (pooler): RobertaPooler(\r\n",
      "      (dense): Linear(in_features=768, out_features=768, bias=True)\r\n",
      "      (activation): Tanh()\r\n",
      "    )\r\n",
      "  )\r\n",
      "  (dropout): Dropout(p=0.1, inplace=False)\r\n",
      "  (classifier): Linear(in_features=768, out_features=1, bias=True)\r\n",
      ")>\r\n",
      "{'return_dict': True, 'output_hidden_states': False, 'output_attentions': False, 'torchscript': False, 'torch_dtype': None, 'use_bfloat16': False, 'tf_legacy_loss': False, 'pruned_heads': {}, 'tie_word_embeddings': True, 'chunk_size_feed_forward': 0, 'is_encoder_decoder': False, 'is_decoder': False, 'cross_attention_hidden_size': None, 'add_cross_attention': False, 'tie_encoder_decoder': False, 'max_length': 20, 'min_length': 0, 'do_sample': False, 'early_stopping': False, 'num_beams': 1, 'num_beam_groups': 1, 'diversity_penalty': 0.0, 'temperature': 1.0, 'top_k': 50, 'top_p': 1.0, 'typical_p': 1.0, 'repetition_penalty': 1.0, 'length_penalty': 1.0, 'no_repeat_ngram_size': 0, 'encoder_no_repeat_ngram_size': 0, 'bad_words_ids': None, 'num_return_sequences': 1, 'output_scores': False, 'return_dict_in_generate': False, 'forced_bos_token_id': None, 'forced_eos_token_id': None, 'remove_invalid_values': False, 'exponential_decay_length_penalty': None, 'suppress_tokens': None, 'begin_suppress_tokens': None, 'architectures': ['RobertaForMaskedLM'], 'finetuning_task': None, 'id2label': {0: 'LABEL_0', 1: 'LABEL_1'}, 'label2id': {'LABEL_0': 0, 'LABEL_1': 1}, 'tokenizer_class': None, 'prefix': None, 'bos_token_id': 0, 'pad_token_id': 1, 'eos_token_id': 2, 'sep_token_id': None, 'decoder_start_token_id': None, 'task_specific_params': None, 'problem_type': None, '_name_or_path': 'FacebookAI/roberta-base', 'transformers_version': '4.37.0', 'model_type': 'roberta', 'vocab_size': 50265, 'hidden_size': 768, 'num_hidden_layers': 12, 'num_attention_heads': 12, 'hidden_act': 'gelu', 'intermediate_size': 3072, 'hidden_dropout_prob': 0.1, 'attention_probs_dropout_prob': 0.1, 'max_position_embeddings': 514, 'type_vocab_size': 1, 'initializer_range': 0.02, 'layer_norm_eps': 1e-05, 'position_embedding_type': 'absolute', 'use_cache': True, 'classifier_dropout': None}\r\n",
      "Downloading and preparing dataset json/default to /root/.cache/huggingface/datasets/json/default-b4ea59149cc0ef60/0.0.0/ac0ca5f5289a6cf108e706efcf040422dbbfa8e658dee6a819f20d76bb84d26b...\r\n",
      "Downloading data files: 100%|███████████████████| 3/3 [00:00<00:00, 9460.84it/s]\r\n",
      "Extracting data files: 100%|████████████████████| 3/3 [00:00<00:00, 1502.62it/s]\r\n",
      "Dataset json downloaded and prepared to /root/.cache/huggingface/datasets/json/default-b4ea59149cc0ef60/0.0.0/ac0ca5f5289a6cf108e706efcf040422dbbfa8e658dee6a819f20d76bb84d26b. Subsequent calls will reuse this data.\r\n",
      "100%|████████████████████████████████████████████| 3/3 [00:00<00:00, 340.73it/s]\r\n",
      "Train data sample: {'id': '7-980', 'question_stem': 'The sun is responsible for', 'choices': {'text': ['puppies learning new tricks', 'children growing up and getting old', 'flowers wilting in a vase', 'plants sprouting, blooming and wilting']}, 'answerKey': 'D', 'facts': ['the sun is the source of energy for life on Earth', 'the sun is the source of energy for physical cycles on Earth', 'the sun is the source of solar energy called sunlight'], 'clue': \"The sun's energy drives photosynthesis, enabling plants to grow, produce oxygen, and ultimately sustain life\"}\r\n",
      "Loaded 1000 samples from OpenBookQA dataset with facts from the book and using clues\r\n",
      "Loaded 500 samples from OpenBookQA dataset with facts from the book and using clues\r\n",
      "Loaded 500 samples from OpenBookQA dataset with facts from the book and using clues\r\n",
      "Train dataset sample: {'input_ids': tensor([[    0,   627,  3778,    16,     5,  1300,     9,  1007,    13,   301,\r\n",
      "            15,  3875,     4,    20,  3778,    18,  1007,  6790,  2356, 43122,\r\n",
      "             6, 10298,  3451,     7,  1733,     6,  2592, 11747,     6,     8,\r\n",
      "          3284,  9844,   301,     4,    20,  3778,    16,  2149,    13,     2,\r\n",
      "             2,   642, 12151,   918,  2239,    92, 15154,     2,     1,     1,\r\n",
      "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\r\n",
      "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\r\n",
      "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\r\n",
      "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\r\n",
      "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\r\n",
      "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\r\n",
      "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\r\n",
      "             1,     1,     1,     1,     1,     1,     1,     1],\r\n",
      "        [    0,   627,  3778,    16,     5,  1300,     9,  1007,    13,   301,\r\n",
      "            15,  3875,     4,    20,  3778,    18,  1007,  6790,  2356, 43122,\r\n",
      "             6, 10298,  3451,     7,  1733,     6,  2592, 11747,     6,     8,\r\n",
      "          3284,  9844,   301,     4,    20,  3778,    16,  2149,    13,     2,\r\n",
      "             2, 15097,  1197,    62,     8,   562,   793,     2,     1,     1,\r\n",
      "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\r\n",
      "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\r\n",
      "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\r\n",
      "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\r\n",
      "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\r\n",
      "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\r\n",
      "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\r\n",
      "             1,     1,     1,     1,     1,     1,     1,     1],\r\n",
      "        [    0,   627,  3778,    16,     5,  1300,     9,  1007,    13,   301,\r\n",
      "            15,  3875,     4,    20,  3778,    18,  1007,  6790,  2356, 43122,\r\n",
      "             6, 10298,  3451,     7,  1733,     6,  2592, 11747,     6,     8,\r\n",
      "          3284,  9844,   301,     4,    20,  3778,    16,  2149,    13,     2,\r\n",
      "             2,  4825,  9945, 27487,  2577,    11,    10,   748,  3175,     2,\r\n",
      "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\r\n",
      "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\r\n",
      "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\r\n",
      "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\r\n",
      "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\r\n",
      "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\r\n",
      "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\r\n",
      "             1,     1,     1,     1,     1,     1,     1,     1],\r\n",
      "        [    0,   627,  3778,    16,     5,  1300,     9,  1007,    13,   301,\r\n",
      "            15,  3875,     4,    20,  3778,    18,  1007,  6790,  2356, 43122,\r\n",
      "             6, 10298,  3451,     7,  1733,     6,  2592, 11747,     6,     8,\r\n",
      "          3284,  9844,   301,     4,    20,  3778,    16,  2149,    13,     2,\r\n",
      "             2,  2911,  3277, 11085, 25754,     6, 20869,  9410,     8, 27487,\r\n",
      "          2577,     2,     1,     1,     1,     1,     1,     1,     1,     1,\r\n",
      "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\r\n",
      "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\r\n",
      "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\r\n",
      "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\r\n",
      "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\r\n",
      "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\r\n",
      "             1,     1,     1,     1,     1,     1,     1,     1]]), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\r\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\r\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\r\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\r\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\r\n",
      "         0, 0, 0, 0, 0, 0, 0, 0],\r\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\r\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\r\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\r\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\r\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\r\n",
      "         0, 0, 0, 0, 0, 0, 0, 0],\r\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\r\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\r\n",
      "         1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\r\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\r\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\r\n",
      "         0, 0, 0, 0, 0, 0, 0, 0],\r\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\r\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\r\n",
      "         1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\r\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\r\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\r\n",
      "         0, 0, 0, 0, 0, 0, 0, 0]]), 'labels': tensor(3)}\r\n",
      "  0%|                                                    | 0/63 [00:00<?, ?it/s]/opt/conda/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\r\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\r\n",
      "100%|███████████████████████████████████████████| 63/63 [00:46<00:00,  1.61it/s]\r\n",
      "  0%|                                                    | 0/32 [00:00<?, ?it/s]\u001b[A\r\n",
      "  6%|██▊                                         | 2/32 [00:00<00:03,  8.23it/s]\u001b[A\r\n",
      "  9%|████▏                                       | 3/32 [00:00<00:05,  5.76it/s]\u001b[A\r\n",
      " 12%|█████▌                                      | 4/32 [00:00<00:05,  4.98it/s]\u001b[A\r\n",
      " 16%|██████▉                                     | 5/32 [00:00<00:05,  4.62it/s]\u001b[A\r\n",
      " 19%|████████▎                                   | 6/32 [00:01<00:05,  4.42it/s]\u001b[A\r\n",
      " 22%|█████████▋                                  | 7/32 [00:01<00:05,  4.31it/s]\u001b[A\r\n",
      " 25%|███████████                                 | 8/32 [00:01<00:05,  4.23it/s]\u001b[A\r\n",
      " 28%|████████████▍                               | 9/32 [00:01<00:05,  4.18it/s]\u001b[A\r\n",
      " 31%|█████████████▍                             | 10/32 [00:02<00:05,  4.15it/s]\u001b[A\r\n",
      " 34%|██████████████▊                            | 11/32 [00:02<00:05,  4.13it/s]\u001b[A\r\n",
      " 38%|████████████████▏                          | 12/32 [00:02<00:04,  4.11it/s]\u001b[A\r\n",
      " 41%|█████████████████▍                         | 13/32 [00:02<00:04,  4.10it/s]\u001b[A\r\n",
      " 44%|██████████████████▊                        | 14/32 [00:03<00:04,  4.09it/s]\u001b[A\r\n",
      " 47%|████████████████████▏                      | 15/32 [00:03<00:04,  4.07it/s]\u001b[A\r\n",
      " 50%|█████████████████████▌                     | 16/32 [00:03<00:03,  4.05it/s]\u001b[A\r\n",
      " 53%|██████████████████████▊                    | 17/32 [00:03<00:03,  4.05it/s]\u001b[A\r\n",
      " 56%|████████████████████████▏                  | 18/32 [00:04<00:03,  4.04it/s]\u001b[A\r\n",
      " 59%|█████████████████████████▌                 | 19/32 [00:04<00:03,  4.04it/s]\u001b[A\r\n",
      " 62%|██████████████████████████▉                | 20/32 [00:04<00:02,  4.04it/s]\u001b[A\r\n",
      " 66%|████████████████████████████▏              | 21/32 [00:04<00:02,  4.05it/s]\u001b[A\r\n",
      " 69%|█████████████████████████████▌             | 22/32 [00:05<00:02,  4.05it/s]\u001b[A\r\n",
      " 72%|██████████████████████████████▉            | 23/32 [00:05<00:02,  4.06it/s]\u001b[A\r\n",
      " 75%|████████████████████████████████▎          | 24/32 [00:05<00:01,  4.07it/s]\u001b[A\r\n",
      " 78%|█████████████████████████████████▌         | 25/32 [00:05<00:01,  4.06it/s]\u001b[A\r\n",
      " 81%|██████████████████████████████████▉        | 26/32 [00:06<00:01,  4.06it/s]\u001b[A\r\n",
      " 84%|████████████████████████████████████▎      | 27/32 [00:06<00:01,  4.06it/s]\u001b[A\r\n",
      " 88%|█████████████████████████████████████▋     | 28/32 [00:06<00:00,  4.06it/s]\u001b[A\r\n",
      " 91%|██████████████████████████████████████▉    | 29/32 [00:06<00:00,  4.07it/s]\u001b[A\r\n",
      " 94%|████████████████████████████████████████▎  | 30/32 [00:07<00:00,  4.05it/s]\u001b[A\r\n",
      " 97%|█████████████████████████████████████████▋ | 31/32 [00:07<00:00,  4.10it/s]\u001b[A\r\n",
      "\r\n",
      "Downloading builder script: 100%|██████████| 4.20k/4.20k [00:00<00:00, 13.8MB/s]\r\n",
      "Accuracy: {'accuracy': 0.654}\r\n",
      "\r\n",
      "{'eval_loss': 1.1259398460388184, 'eval_accuracy': 0.654, 'eval_runtime': 8.3714, 'eval_samples_per_second': 59.727, 'eval_steps_per_second': 3.823, 'epoch': 1.0}\r\n",
      "\r\n",
      "100%|███████████████████████████████████████████| 63/63 [00:55<00:00,  1.61it/s]\r\n",
      "{'train_runtime': 57.842, 'train_samples_per_second': 17.288, 'train_steps_per_second': 1.089, 'train_loss': 1.3505829099624875, 'epoch': 1.0}\r\n",
      "100%|███████████████████████████████████████████| 63/63 [00:57<00:00,  1.09it/s]\r\n",
      "/opt/conda/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\r\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\r\n",
      " 97%|█████████████████████████████████████████▋ | 31/32 [00:07<00:00,  4.00it/s]Accuracy: {'accuracy': 0.654}\r\n",
      "100%|███████████████████████████████████████████| 32/32 [00:07<00:00,  4.03it/s]\r\n",
      "/opt/conda/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\r\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\r\n",
      " 97%|█████████████████████████████████████████▋ | 31/32 [00:07<00:00,  4.03it/s]Accuracy: {'accuracy': 0.654}\r\n",
      "100%|███████████████████████████████████████████| 32/32 [00:07<00:00,  4.00it/s]\r\n"
     ]
    }
   ],
   "source": [
    "!CUDA_VISIBLE_DEVICES=0,1 python train.py --model \"FacebookAI/roberta-base\" --output_dir checkpoints/roberta-base_obqa_1facts_clues_5 --num_train_epochs 1 --use_book True --use_clue True  --n_facts 1 --report_to=\"none\" --do_train --do_eval --per_device_train_batch_size 8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "412a5087",
   "metadata": {
    "papermill": {
     "duration": 0.022984,
     "end_time": "2024-03-11T07:02:25.989514",
     "exception": false,
     "start_time": "2024-03-11T07:02:25.966530",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "nvidiaTeslaT4",
   "dataSources": [
    {
     "datasetId": 4529429,
     "sourceId": 7747977,
     "sourceType": "datasetVersion"
    }
   ],
   "dockerImageVersionId": 30648,
   "isGpuEnabled": true,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 150.773732,
   "end_time": "2024-03-11T07:02:26.733904",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2024-03-11T06:59:55.960172",
   "version": "2.5.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
