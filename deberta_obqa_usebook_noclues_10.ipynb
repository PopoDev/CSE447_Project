{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "144da091",
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "execution": {
     "iopub.execute_input": "2024-03-10T18:55:12.067898Z",
     "iopub.status.busy": "2024-03-10T18:55:12.067566Z",
     "iopub.status.idle": "2024-03-10T18:55:12.935812Z",
     "shell.execute_reply": "2024-03-10T18:55:12.934933Z"
    },
    "papermill": {
     "duration": 0.875804,
     "end_time": "2024-03-10T18:55:12.938020",
     "exception": false,
     "start_time": "2024-03-10T18:55:12.062216",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/kaggle/input/cse447-models/model.safetensors\n"
     ]
    }
   ],
   "source": [
    "# This Python 3 environment comes with many helpful analytics libraries installed\n",
    "# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n",
    "# For example, here's several helpful packages to load\n",
    "\n",
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "\n",
    "# Input data files are available in the read-only \"../input/\" directory\n",
    "# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n",
    "\n",
    "import os\n",
    "for dirname, _, filenames in os.walk('/kaggle/input'):\n",
    "    for filename in filenames:\n",
    "        print(os.path.join(dirname, filename))\n",
    "\n",
    "# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n",
    "# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "80f66b4b",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-03-10T18:55:12.947590Z",
     "iopub.status.busy": "2024-03-10T18:55:12.947188Z",
     "iopub.status.idle": "2024-03-10T18:55:15.562961Z",
     "shell.execute_reply": "2024-03-10T18:55:15.561578Z"
    },
    "papermill": {
     "duration": 2.623669,
     "end_time": "2024-03-10T18:55:15.566079",
     "exception": false,
     "start_time": "2024-03-10T18:55:12.942410",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cloning into 'CSE447_Project'...\r\n",
      "remote: Enumerating objects: 311, done.\u001b[K\r\n",
      "remote: Counting objects: 100% (50/50), done.\u001b[K\r\n",
      "remote: Compressing objects: 100% (33/33), done.\u001b[K\r\n",
      "remote: Total 311 (delta 20), reused 39 (delta 15), pack-reused 261\u001b[K\r\n",
      "Receiving objects: 100% (311/311), 10.97 MiB | 16.01 MiB/s, done.\r\n",
      "Resolving deltas: 100% (166/166), done.\r\n"
     ]
    }
   ],
   "source": [
    "!git clone https://github.com/PopoDev/CSE447_Project.git"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "546447b8",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-03-10T18:55:15.580503Z",
     "iopub.status.busy": "2024-03-10T18:55:15.579764Z",
     "iopub.status.idle": "2024-03-10T18:55:16.562415Z",
     "shell.execute_reply": "2024-03-10T18:55:16.561534Z"
    },
    "papermill": {
     "duration": 0.991705,
     "end_time": "2024-03-10T18:55:16.564692",
     "exception": false,
     "start_time": "2024-03-10T18:55:15.572987",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[0m\u001b[01;34mCSE447_Project\u001b[0m/  __notebook__.ipynb\r\n"
     ]
    }
   ],
   "source": [
    "ls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "41a0ac3d",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-03-10T18:55:16.575776Z",
     "iopub.status.busy": "2024-03-10T18:55:16.575427Z",
     "iopub.status.idle": "2024-03-10T18:55:16.581392Z",
     "shell.execute_reply": "2024-03-10T18:55:16.580552Z"
    },
    "papermill": {
     "duration": 0.013939,
     "end_time": "2024-03-10T18:55:16.583507",
     "exception": false,
     "start_time": "2024-03-10T18:55:16.569568",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/kaggle/working/CSE447_Project\n"
     ]
    }
   ],
   "source": [
    "cd CSE447_Project/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "099df33a",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-03-10T18:55:16.594346Z",
     "iopub.status.busy": "2024-03-10T18:55:16.594096Z",
     "iopub.status.idle": "2024-03-10T18:55:17.721563Z",
     "shell.execute_reply": "2024-03-10T18:55:17.720407Z"
    },
    "papermill": {
     "duration": 1.135186,
     "end_time": "2024-03-10T18:55:17.723774",
     "exception": false,
     "start_time": "2024-03-10T18:55:16.588588",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Already up to date.\r\n"
     ]
    }
   ],
   "source": [
    "!git pull"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e33a787",
   "metadata": {
    "papermill": {
     "duration": 0.004772,
     "end_time": "2024-03-10T18:55:17.733584",
     "exception": false,
     "start_time": "2024-03-10T18:55:17.728812",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Student"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "10f6db58",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-03-10T18:55:17.744500Z",
     "iopub.status.busy": "2024-03-10T18:55:17.744162Z",
     "iopub.status.idle": "2024-03-10T18:55:17.750261Z",
     "shell.execute_reply": "2024-03-10T18:55:17.749251Z"
    },
    "papermill": {
     "duration": 0.01394,
     "end_time": "2024-03-10T18:55:17.752205",
     "exception": false,
     "start_time": "2024-03-10T18:55:17.738265",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/kaggle/working/CSE447_Project/Student\n"
     ]
    }
   ],
   "source": [
    "cd /kaggle/working/CSE447_Project/Student"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "33532f74",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-03-10T18:55:17.762876Z",
     "iopub.status.busy": "2024-03-10T18:55:17.762625Z",
     "iopub.status.idle": "2024-03-10T18:55:18.707668Z",
     "shell.execute_reply": "2024-03-10T18:55:18.706758Z"
    },
    "papermill": {
     "duration": 0.953016,
     "end_time": "2024-03-10T18:55:18.709997",
     "exception": false,
     "start_time": "2024-03-10T18:55:17.756981",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "arguments.py  \u001b[0m\u001b[01;34mdataloader\u001b[0m/  requirements.txt  run_sbert.py  \u001b[01;34mutils\u001b[0m/\r\n",
      "\u001b[01;34mdata\u001b[0m/         \u001b[01;34mmodel\u001b[0m/       run.py            train.py\r\n"
     ]
    }
   ],
   "source": [
    "ls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "60cdb3a6",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-03-10T18:55:18.721850Z",
     "iopub.status.busy": "2024-03-10T18:55:18.721550Z",
     "iopub.status.idle": "2024-03-10T18:55:33.606675Z",
     "shell.execute_reply": "2024-03-10T18:55:33.605528Z"
    },
    "papermill": {
     "duration": 14.893762,
     "end_time": "2024-03-10T18:55:33.609184",
     "exception": false,
     "start_time": "2024-03-10T18:55:18.715422",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting sentence-transformers (from -r requirements.txt (line 1))\r\n",
      "  Downloading sentence_transformers-2.5.1-py3-none-any.whl.metadata (11 kB)\r\n",
      "Collecting evaluate (from -r requirements.txt (line 2))\r\n",
      "  Downloading evaluate-0.4.1-py3-none-any.whl.metadata (9.4 kB)\r\n",
      "Requirement already satisfied: transformers<5.0.0,>=4.32.0 in /opt/conda/lib/python3.10/site-packages (from sentence-transformers->-r requirements.txt (line 1)) (4.37.0)\r\n",
      "Requirement already satisfied: tqdm in /opt/conda/lib/python3.10/site-packages (from sentence-transformers->-r requirements.txt (line 1)) (4.66.1)\r\n",
      "Requirement already satisfied: torch>=1.11.0 in /opt/conda/lib/python3.10/site-packages (from sentence-transformers->-r requirements.txt (line 1)) (2.1.2)\r\n",
      "Requirement already satisfied: numpy in /opt/conda/lib/python3.10/site-packages (from sentence-transformers->-r requirements.txt (line 1)) (1.24.4)\r\n",
      "Requirement already satisfied: scikit-learn in /opt/conda/lib/python3.10/site-packages (from sentence-transformers->-r requirements.txt (line 1)) (1.2.2)\r\n",
      "Requirement already satisfied: scipy in /opt/conda/lib/python3.10/site-packages (from sentence-transformers->-r requirements.txt (line 1)) (1.11.4)\r\n",
      "Requirement already satisfied: huggingface-hub>=0.15.1 in /opt/conda/lib/python3.10/site-packages (from sentence-transformers->-r requirements.txt (line 1)) (0.20.3)\r\n",
      "Requirement already satisfied: Pillow in /opt/conda/lib/python3.10/site-packages (from sentence-transformers->-r requirements.txt (line 1)) (9.5.0)\r\n",
      "Requirement already satisfied: datasets>=2.0.0 in /opt/conda/lib/python3.10/site-packages (from evaluate->-r requirements.txt (line 2)) (2.1.0)\r\n",
      "Requirement already satisfied: dill in /opt/conda/lib/python3.10/site-packages (from evaluate->-r requirements.txt (line 2)) (0.3.7)\r\n",
      "Requirement already satisfied: pandas in /opt/conda/lib/python3.10/site-packages (from evaluate->-r requirements.txt (line 2)) (2.1.4)\r\n",
      "Requirement already satisfied: requests>=2.19.0 in /opt/conda/lib/python3.10/site-packages (from evaluate->-r requirements.txt (line 2)) (2.31.0)\r\n",
      "Requirement already satisfied: xxhash in /opt/conda/lib/python3.10/site-packages (from evaluate->-r requirements.txt (line 2)) (3.4.1)\r\n",
      "Requirement already satisfied: multiprocess in /opt/conda/lib/python3.10/site-packages (from evaluate->-r requirements.txt (line 2)) (0.70.15)\r\n",
      "Requirement already satisfied: fsspec>=2021.05.0 in /opt/conda/lib/python3.10/site-packages (from fsspec[http]>=2021.05.0->evaluate->-r requirements.txt (line 2)) (2023.12.2)\r\n",
      "Requirement already satisfied: packaging in /opt/conda/lib/python3.10/site-packages (from evaluate->-r requirements.txt (line 2)) (21.3)\r\n",
      "Requirement already satisfied: responses<0.19 in /opt/conda/lib/python3.10/site-packages (from evaluate->-r requirements.txt (line 2)) (0.18.0)\r\n",
      "Requirement already satisfied: pyarrow>=5.0.0 in /opt/conda/lib/python3.10/site-packages (from datasets>=2.0.0->evaluate->-r requirements.txt (line 2)) (11.0.0)\r\n",
      "Requirement already satisfied: aiohttp in /opt/conda/lib/python3.10/site-packages (from datasets>=2.0.0->evaluate->-r requirements.txt (line 2)) (3.9.1)\r\n",
      "Requirement already satisfied: filelock in /opt/conda/lib/python3.10/site-packages (from huggingface-hub>=0.15.1->sentence-transformers->-r requirements.txt (line 1)) (3.13.1)\r\n",
      "Requirement already satisfied: pyyaml>=5.1 in /opt/conda/lib/python3.10/site-packages (from huggingface-hub>=0.15.1->sentence-transformers->-r requirements.txt (line 1)) (6.0.1)\r\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /opt/conda/lib/python3.10/site-packages (from huggingface-hub>=0.15.1->sentence-transformers->-r requirements.txt (line 1)) (4.9.0)\r\n",
      "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /opt/conda/lib/python3.10/site-packages (from packaging->evaluate->-r requirements.txt (line 2)) (3.1.1)\r\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.10/site-packages (from requests>=2.19.0->evaluate->-r requirements.txt (line 2)) (3.3.2)\r\n",
      "Requirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.10/site-packages (from requests>=2.19.0->evaluate->-r requirements.txt (line 2)) (3.6)\r\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /opt/conda/lib/python3.10/site-packages (from requests>=2.19.0->evaluate->-r requirements.txt (line 2)) (1.26.18)\r\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.10/site-packages (from requests>=2.19.0->evaluate->-r requirements.txt (line 2)) (2023.11.17)\r\n",
      "Requirement already satisfied: sympy in /opt/conda/lib/python3.10/site-packages (from torch>=1.11.0->sentence-transformers->-r requirements.txt (line 1)) (1.12)\r\n",
      "Requirement already satisfied: networkx in /opt/conda/lib/python3.10/site-packages (from torch>=1.11.0->sentence-transformers->-r requirements.txt (line 1)) (3.2.1)\r\n",
      "Requirement already satisfied: jinja2 in /opt/conda/lib/python3.10/site-packages (from torch>=1.11.0->sentence-transformers->-r requirements.txt (line 1)) (3.1.2)\r\n",
      "Requirement already satisfied: regex!=2019.12.17 in /opt/conda/lib/python3.10/site-packages (from transformers<5.0.0,>=4.32.0->sentence-transformers->-r requirements.txt (line 1)) (2023.12.25)\r\n",
      "Requirement already satisfied: tokenizers<0.19,>=0.14 in /opt/conda/lib/python3.10/site-packages (from transformers<5.0.0,>=4.32.0->sentence-transformers->-r requirements.txt (line 1)) (0.15.1)\r\n",
      "Requirement already satisfied: safetensors>=0.3.1 in /opt/conda/lib/python3.10/site-packages (from transformers<5.0.0,>=4.32.0->sentence-transformers->-r requirements.txt (line 1)) (0.4.2)\r\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /opt/conda/lib/python3.10/site-packages (from pandas->evaluate->-r requirements.txt (line 2)) (2.8.2)\r\n",
      "Requirement already satisfied: pytz>=2020.1 in /opt/conda/lib/python3.10/site-packages (from pandas->evaluate->-r requirements.txt (line 2)) (2023.3.post1)\r\n",
      "Requirement already satisfied: tzdata>=2022.1 in /opt/conda/lib/python3.10/site-packages (from pandas->evaluate->-r requirements.txt (line 2)) (2023.4)\r\n",
      "Requirement already satisfied: joblib>=1.1.1 in /opt/conda/lib/python3.10/site-packages (from scikit-learn->sentence-transformers->-r requirements.txt (line 1)) (1.3.2)\r\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in /opt/conda/lib/python3.10/site-packages (from scikit-learn->sentence-transformers->-r requirements.txt (line 1)) (3.2.0)\r\n",
      "Requirement already satisfied: attrs>=17.3.0 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets>=2.0.0->evaluate->-r requirements.txt (line 2)) (23.2.0)\r\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets>=2.0.0->evaluate->-r requirements.txt (line 2)) (6.0.4)\r\n",
      "Requirement already satisfied: yarl<2.0,>=1.0 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets>=2.0.0->evaluate->-r requirements.txt (line 2)) (1.9.3)\r\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets>=2.0.0->evaluate->-r requirements.txt (line 2)) (1.4.1)\r\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets>=2.0.0->evaluate->-r requirements.txt (line 2)) (1.3.1)\r\n",
      "Requirement already satisfied: async-timeout<5.0,>=4.0 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets>=2.0.0->evaluate->-r requirements.txt (line 2)) (4.0.3)\r\n",
      "Requirement already satisfied: six>=1.5 in /opt/conda/lib/python3.10/site-packages (from python-dateutil>=2.8.2->pandas->evaluate->-r requirements.txt (line 2)) (1.16.0)\r\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /opt/conda/lib/python3.10/site-packages (from jinja2->torch>=1.11.0->sentence-transformers->-r requirements.txt (line 1)) (2.1.3)\r\n",
      "Requirement already satisfied: mpmath>=0.19 in /opt/conda/lib/python3.10/site-packages (from sympy->torch>=1.11.0->sentence-transformers->-r requirements.txt (line 1)) (1.3.0)\r\n",
      "Downloading sentence_transformers-2.5.1-py3-none-any.whl (156 kB)\r\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m156.5/156.5 kB\u001b[0m \u001b[31m1.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25hDownloading evaluate-0.4.1-py3-none-any.whl (84 kB)\r\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m84.1/84.1 kB\u001b[0m \u001b[31m4.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25hInstalling collected packages: sentence-transformers, evaluate\r\n",
      "Successfully installed evaluate-0.4.1 sentence-transformers-2.5.1\r\n"
     ]
    }
   ],
   "source": [
    "!pip install -r requirements.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "2c684f42",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-03-10T18:55:33.625077Z",
     "iopub.status.busy": "2024-03-10T18:55:33.624753Z",
     "iopub.status.idle": "2024-03-10T18:55:38.862846Z",
     "shell.execute_reply": "2024-03-10T18:55:38.861455Z"
    },
    "papermill": {
     "duration": 5.248763,
     "end_time": "2024-03-10T18:55:38.865181",
     "exception": false,
     "start_time": "2024-03-10T18:55:33.616418",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sun Mar 10 18:55:38 2024       \r\n",
      "+---------------------------------------------------------------------------------------+\r\n",
      "| NVIDIA-SMI 535.129.03             Driver Version: 535.129.03   CUDA Version: 12.2     |\r\n",
      "|-----------------------------------------+----------------------+----------------------+\r\n",
      "| GPU  Name                 Persistence-M | Bus-Id        Disp.A | Volatile Uncorr. ECC |\r\n",
      "| Fan  Temp   Perf          Pwr:Usage/Cap |         Memory-Usage | GPU-Util  Compute M. |\r\n",
      "|                                         |                      |               MIG M. |\r\n",
      "|=========================================+======================+======================|\r\n",
      "|   0  Tesla T4                       Off | 00000000:00:04.0 Off |                    0 |\r\n",
      "| N/A   46C    P8              10W /  70W |      0MiB / 15360MiB |      0%      Default |\r\n",
      "|                                         |                      |                  N/A |\r\n",
      "+-----------------------------------------+----------------------+----------------------+\r\n",
      "|   1  Tesla T4                       Off | 00000000:00:05.0 Off |                    0 |\r\n",
      "| N/A   47C    P8              10W /  70W |      0MiB / 15360MiB |      0%      Default |\r\n",
      "|                                         |                      |                  N/A |\r\n",
      "+-----------------------------------------+----------------------+----------------------+\r\n",
      "                                                                                         \r\n",
      "+---------------------------------------------------------------------------------------+\r\n",
      "| Processes:                                                                            |\r\n",
      "|  GPU   GI   CI        PID   Type   Process name                            GPU Memory |\r\n",
      "|        ID   ID                                                             Usage      |\r\n",
      "|=======================================================================================|\r\n",
      "|  No running processes found                                                           |\r\n",
      "+---------------------------------------------------------------------------------------+\r\n"
     ]
    }
   ],
   "source": [
    "import gc\n",
    "import torch\n",
    "\n",
    "model = None\n",
    "gc.collect()\n",
    "torch.cuda.empty_cache()\n",
    "!nvidia-smi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "a6d8b031",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-03-10T18:55:38.882094Z",
     "iopub.status.busy": "2024-03-10T18:55:38.880921Z",
     "iopub.status.idle": "2024-03-10T20:03:09.225924Z",
     "shell.execute_reply": "2024-03-10T20:03:09.224557Z"
    },
    "papermill": {
     "duration": 4050.357379,
     "end_time": "2024-03-10T20:03:09.229992",
     "exception": false,
     "start_time": "2024-03-10T18:55:38.872613",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-03-10 18:55:46.710142: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:9261] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\r\n",
      "2024-03-10 18:55:46.710279: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:607] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\r\n",
      "2024-03-10 18:55:46.878379: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1515] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\r\n",
      "tokenizer_config.json: 100%|██████████████████| 52.0/52.0 [00:00<00:00, 249kB/s]\r\n",
      "config.json: 100%|█████████████████████████████| 579/579 [00:00<00:00, 3.24MB/s]\r\n",
      "spm.model: 100%|███████████████████████████| 2.46M/2.46M [00:00<00:00, 30.6MB/s]\r\n",
      "/opt/conda/lib/python3.10/site-packages/transformers/convert_slow_tokenizer.py:515: UserWarning: The sentencepiece tokenizer that you are converting to a fast tokenizer uses the byte fallback option which is not implemented in the fast tokenizers. In practice this means that the fast version of the tokenizer can produce unknown tokens whereas the sentencepiece version would have converted these unknown tokens into a sequence of byte tokens matching the original piece of text.\r\n",
      "  warnings.warn(\r\n",
      "pytorch_model.bin: 100%|██████████████████████| 371M/371M [00:01<00:00, 213MB/s]\r\n",
      "/opt/conda/lib/python3.10/site-packages/torch/_utils.py:831: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()\r\n",
      "  return self.fget.__get__(instance, owner)()\r\n",
      "Some weights of DebertaV2ForMultipleChoice were not initialized from the model checkpoint at microsoft/deberta-v3-base and are newly initialized: ['classifier.bias', 'classifier.weight', 'pooler.dense.bias', 'pooler.dense.weight']\r\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\r\n",
      "<bound method Module.parameters of DebertaV2ForMultipleChoice(\r\n",
      "  (deberta): DebertaV2Model(\r\n",
      "    (embeddings): DebertaV2Embeddings(\r\n",
      "      (word_embeddings): Embedding(128100, 768, padding_idx=0)\r\n",
      "      (LayerNorm): LayerNorm((768,), eps=1e-07, elementwise_affine=True)\r\n",
      "      (dropout): StableDropout()\r\n",
      "    )\r\n",
      "    (encoder): DebertaV2Encoder(\r\n",
      "      (layer): ModuleList(\r\n",
      "        (0-11): 12 x DebertaV2Layer(\r\n",
      "          (attention): DebertaV2Attention(\r\n",
      "            (self): DisentangledSelfAttention(\r\n",
      "              (query_proj): Linear(in_features=768, out_features=768, bias=True)\r\n",
      "              (key_proj): Linear(in_features=768, out_features=768, bias=True)\r\n",
      "              (value_proj): Linear(in_features=768, out_features=768, bias=True)\r\n",
      "              (pos_dropout): StableDropout()\r\n",
      "              (dropout): StableDropout()\r\n",
      "            )\r\n",
      "            (output): DebertaV2SelfOutput(\r\n",
      "              (dense): Linear(in_features=768, out_features=768, bias=True)\r\n",
      "              (LayerNorm): LayerNorm((768,), eps=1e-07, elementwise_affine=True)\r\n",
      "              (dropout): StableDropout()\r\n",
      "            )\r\n",
      "          )\r\n",
      "          (intermediate): DebertaV2Intermediate(\r\n",
      "            (dense): Linear(in_features=768, out_features=3072, bias=True)\r\n",
      "            (intermediate_act_fn): GELUActivation()\r\n",
      "          )\r\n",
      "          (output): DebertaV2Output(\r\n",
      "            (dense): Linear(in_features=3072, out_features=768, bias=True)\r\n",
      "            (LayerNorm): LayerNorm((768,), eps=1e-07, elementwise_affine=True)\r\n",
      "            (dropout): StableDropout()\r\n",
      "          )\r\n",
      "        )\r\n",
      "      )\r\n",
      "      (rel_embeddings): Embedding(512, 768)\r\n",
      "      (LayerNorm): LayerNorm((768,), eps=1e-07, elementwise_affine=True)\r\n",
      "    )\r\n",
      "  )\r\n",
      "  (pooler): ContextPooler(\r\n",
      "    (dense): Linear(in_features=768, out_features=768, bias=True)\r\n",
      "    (dropout): StableDropout()\r\n",
      "  )\r\n",
      "  (classifier): Linear(in_features=768, out_features=1, bias=True)\r\n",
      "  (dropout): StableDropout()\r\n",
      ")>\r\n",
      "{'return_dict': True, 'output_hidden_states': False, 'output_attentions': False, 'torchscript': False, 'torch_dtype': None, 'use_bfloat16': False, 'tf_legacy_loss': False, 'pruned_heads': {}, 'tie_word_embeddings': True, 'chunk_size_feed_forward': 0, 'is_encoder_decoder': False, 'is_decoder': False, 'cross_attention_hidden_size': None, 'add_cross_attention': False, 'tie_encoder_decoder': False, 'max_length': 20, 'min_length': 0, 'do_sample': False, 'early_stopping': False, 'num_beams': 1, 'num_beam_groups': 1, 'diversity_penalty': 0.0, 'temperature': 1.0, 'top_k': 50, 'top_p': 1.0, 'typical_p': 1.0, 'repetition_penalty': 1.0, 'length_penalty': 1.0, 'no_repeat_ngram_size': 0, 'encoder_no_repeat_ngram_size': 0, 'bad_words_ids': None, 'num_return_sequences': 1, 'output_scores': False, 'return_dict_in_generate': False, 'forced_bos_token_id': None, 'forced_eos_token_id': None, 'remove_invalid_values': False, 'exponential_decay_length_penalty': None, 'suppress_tokens': None, 'begin_suppress_tokens': None, 'architectures': None, 'finetuning_task': None, 'id2label': {0: 'LABEL_0', 1: 'LABEL_1'}, 'label2id': {'LABEL_0': 0, 'LABEL_1': 1}, 'tokenizer_class': None, 'prefix': None, 'bos_token_id': None, 'pad_token_id': 0, 'eos_token_id': None, 'sep_token_id': None, 'decoder_start_token_id': None, 'task_specific_params': None, 'problem_type': None, '_name_or_path': 'microsoft/deberta-v3-base', 'transformers_version': '4.37.0', 'model_type': 'deberta-v2', 'position_buckets': 256, 'norm_rel_ebd': 'layer_norm', 'share_att_key': True, 'hidden_size': 768, 'num_hidden_layers': 12, 'num_attention_heads': 12, 'intermediate_size': 3072, 'hidden_act': 'gelu', 'hidden_dropout_prob': 0.1, 'attention_probs_dropout_prob': 0.1, 'max_position_embeddings': 512, 'type_vocab_size': 0, 'initializer_range': 0.02, 'relative_attention': True, 'max_relative_positions': -1, 'position_biased_input': False, 'pos_att_type': ['p2c', 'c2p'], 'vocab_size': 128100, 'layer_norm_eps': 1e-07, 'pooler_hidden_size': 768, 'pooler_dropout': 0, 'pooler_hidden_act': 'gelu'}\r\n",
      "Downloading and preparing dataset json/default to /root/.cache/huggingface/datasets/json/default-c1638f0e88587610/0.0.0/ac0ca5f5289a6cf108e706efcf040422dbbfa8e658dee6a819f20d76bb84d26b...\r\n",
      "Downloading data files: 100%|███████████████████| 3/3 [00:00<00:00, 9539.74it/s]\r\n",
      "Extracting data files: 100%|████████████████████| 3/3 [00:00<00:00, 1586.95it/s]\r\n",
      "Dataset json downloaded and prepared to /root/.cache/huggingface/datasets/json/default-c1638f0e88587610/0.0.0/ac0ca5f5289a6cf108e706efcf040422dbbfa8e658dee6a819f20d76bb84d26b. Subsequent calls will reuse this data.\r\n",
      "100%|████████████████████████████████████████████| 3/3 [00:00<00:00, 432.40it/s]\r\n",
      "Train data sample: {'id': '7-980', 'question_stem': 'The sun is responsible for', 'choices': {'text': ['puppies learning new tricks', 'children growing up and getting old', 'flowers wilting in a vase', 'plants sprouting, blooming and wilting']}, 'answerKey': 'D', 'facts': ['the sun is the source of energy for life on Earth', 'the sun is the source of energy for physical cycles on Earth', 'the sun is the source of solar energy called sunlight']}\r\n",
      "Loaded 4957 samples from OpenBookQA dataset with facts from the book\r\n",
      "Loaded 500 samples from OpenBookQA dataset with facts from the book\r\n",
      "Loaded 500 samples from OpenBookQA dataset with facts from the book\r\n",
      "Train dataset sample: {'input_ids': tensor([[     1,    262,   2119,    269,    262,   1271,    265,    843,    270,\r\n",
      "            432,    277,   2610,    260,    279,   2119,    269,   1744,    270,\r\n",
      "              2,  15804,   1101,    353,   7604,      2,      0,      0,      0,\r\n",
      "              0,      0,      0,      0,      0,      0,      0,      0,      0,\r\n",
      "              0,      0,      0,      0,      0,      0,      0,      0,      0,\r\n",
      "              0,      0,      0,      0,      0,      0,      0,      0,      0,\r\n",
      "              0,      0,      0,      0,      0,      0,      0,      0,      0,\r\n",
      "              0,      0,      0,      0,      0,      0,      0,      0,      0,\r\n",
      "              0,      0,      0,      0,      0,      0,      0,      0,      0,\r\n",
      "              0,      0,      0,      0,      0,      0,      0,      0,      0,\r\n",
      "              0,      0,      0,      0,      0,      0,      0,      0,      0,\r\n",
      "              0,      0,      0,      0,      0,      0,      0,      0,      0,\r\n",
      "              0,      0,      0,      0,      0,      0,      0,      0,      0,\r\n",
      "              0,      0,      0,      0,      0,      0,      0,      0,      0,\r\n",
      "              0,      0],\r\n",
      "        [     1,    262,   2119,    269,    262,   1271,    265,    843,    270,\r\n",
      "            432,    277,   2610,    260,    279,   2119,    269,   1744,    270,\r\n",
      "              2,    572,   1479,    322,    263,    646,    597,      2,      0,\r\n",
      "              0,      0,      0,      0,      0,      0,      0,      0,      0,\r\n",
      "              0,      0,      0,      0,      0,      0,      0,      0,      0,\r\n",
      "              0,      0,      0,      0,      0,      0,      0,      0,      0,\r\n",
      "              0,      0,      0,      0,      0,      0,      0,      0,      0,\r\n",
      "              0,      0,      0,      0,      0,      0,      0,      0,      0,\r\n",
      "              0,      0,      0,      0,      0,      0,      0,      0,      0,\r\n",
      "              0,      0,      0,      0,      0,      0,      0,      0,      0,\r\n",
      "              0,      0,      0,      0,      0,      0,      0,      0,      0,\r\n",
      "              0,      0,      0,      0,      0,      0,      0,      0,      0,\r\n",
      "              0,      0,      0,      0,      0,      0,      0,      0,      0,\r\n",
      "              0,      0,      0,      0,      0,      0,      0,      0,      0,\r\n",
      "              0,      0],\r\n",
      "        [     1,    262,   2119,    269,    262,   1271,    265,    843,    270,\r\n",
      "            432,    277,   2610,    260,    279,   2119,    269,   1744,    270,\r\n",
      "              2,   2948, 105902,    267,    266,  19502,      2,      0,      0,\r\n",
      "              0,      0,      0,      0,      0,      0,      0,      0,      0,\r\n",
      "              0,      0,      0,      0,      0,      0,      0,      0,      0,\r\n",
      "              0,      0,      0,      0,      0,      0,      0,      0,      0,\r\n",
      "              0,      0,      0,      0,      0,      0,      0,      0,      0,\r\n",
      "              0,      0,      0,      0,      0,      0,      0,      0,      0,\r\n",
      "              0,      0,      0,      0,      0,      0,      0,      0,      0,\r\n",
      "              0,      0,      0,      0,      0,      0,      0,      0,      0,\r\n",
      "              0,      0,      0,      0,      0,      0,      0,      0,      0,\r\n",
      "              0,      0,      0,      0,      0,      0,      0,      0,      0,\r\n",
      "              0,      0,      0,      0,      0,      0,      0,      0,      0,\r\n",
      "              0,      0,      0,      0,      0,      0,      0,      0,      0,\r\n",
      "              0,      0],\r\n",
      "        [     1,    262,   2119,    269,    262,   1271,    265,    843,    270,\r\n",
      "            432,    277,   2610,    260,    279,   2119,    269,   1744,    270,\r\n",
      "              2,   2239,  51081,    261,  24654,    263, 105902,      2,      0,\r\n",
      "              0,      0,      0,      0,      0,      0,      0,      0,      0,\r\n",
      "              0,      0,      0,      0,      0,      0,      0,      0,      0,\r\n",
      "              0,      0,      0,      0,      0,      0,      0,      0,      0,\r\n",
      "              0,      0,      0,      0,      0,      0,      0,      0,      0,\r\n",
      "              0,      0,      0,      0,      0,      0,      0,      0,      0,\r\n",
      "              0,      0,      0,      0,      0,      0,      0,      0,      0,\r\n",
      "              0,      0,      0,      0,      0,      0,      0,      0,      0,\r\n",
      "              0,      0,      0,      0,      0,      0,      0,      0,      0,\r\n",
      "              0,      0,      0,      0,      0,      0,      0,      0,      0,\r\n",
      "              0,      0,      0,      0,      0,      0,      0,      0,      0,\r\n",
      "              0,      0,      0,      0,      0,      0,      0,      0,      0,\r\n",
      "              0,      0]]), 'token_type_ids': tensor([[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1,\r\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\r\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\r\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\r\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\r\n",
      "         0, 0, 0, 0, 0, 0, 0, 0],\r\n",
      "        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1,\r\n",
      "         1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\r\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\r\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\r\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\r\n",
      "         0, 0, 0, 0, 0, 0, 0, 0],\r\n",
      "        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1,\r\n",
      "         1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\r\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\r\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\r\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\r\n",
      "         0, 0, 0, 0, 0, 0, 0, 0],\r\n",
      "        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1,\r\n",
      "         1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\r\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\r\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\r\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\r\n",
      "         0, 0, 0, 0, 0, 0, 0, 0]]), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\r\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\r\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\r\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\r\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\r\n",
      "         0, 0, 0, 0, 0, 0, 0, 0],\r\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\r\n",
      "         1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\r\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\r\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\r\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\r\n",
      "         0, 0, 0, 0, 0, 0, 0, 0],\r\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\r\n",
      "         1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\r\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\r\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\r\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\r\n",
      "         0, 0, 0, 0, 0, 0, 0, 0],\r\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\r\n",
      "         1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\r\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\r\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\r\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\r\n",
      "         0, 0, 0, 0, 0, 0, 0, 0]]), 'labels': tensor(3)}\r\n",
      "  0%|                                                  | 0/6200 [00:00<?, ?it/s]/opt/conda/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\r\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\r\n",
      "{'loss': 0.8746, 'learning_rate': 4.596774193548387e-05, 'epoch': 0.81}\r\n",
      " 10%|████                                    | 620/6200 [06:24<54:21,  1.71it/s]\r\n",
      "  0%|                                                    | 0/32 [00:00<?, ?it/s]\u001b[A\r\n",
      "  6%|██▊                                         | 2/32 [00:00<00:05,  5.76it/s]\u001b[A\r\n",
      "  9%|████▏                                       | 3/32 [00:00<00:07,  4.06it/s]\u001b[A\r\n",
      " 12%|█████▌                                      | 4/32 [00:01<00:07,  3.52it/s]\u001b[A\r\n",
      " 16%|██████▉                                     | 5/32 [00:01<00:08,  3.26it/s]\u001b[A\r\n",
      " 19%|████████▎                                   | 6/32 [00:01<00:08,  3.13it/s]\u001b[A\r\n",
      " 22%|█████████▋                                  | 7/32 [00:02<00:08,  3.04it/s]\u001b[A\r\n",
      " 25%|███████████                                 | 8/32 [00:02<00:08,  2.99it/s]\u001b[A\r\n",
      " 28%|████████████▍                               | 9/32 [00:02<00:07,  2.96it/s]\u001b[A\r\n",
      " 31%|█████████████▍                             | 10/32 [00:03<00:07,  2.93it/s]\u001b[A\r\n",
      " 34%|██████████████▊                            | 11/32 [00:03<00:07,  2.92it/s]\u001b[A\r\n",
      " 38%|████████████████▏                          | 12/32 [00:03<00:06,  2.90it/s]\u001b[A\r\n",
      " 41%|█████████████████▍                         | 13/32 [00:04<00:06,  2.89it/s]\u001b[A\r\n",
      " 44%|██████████████████▊                        | 14/32 [00:04<00:06,  2.88it/s]\u001b[A\r\n",
      " 47%|████████████████████▏                      | 15/32 [00:04<00:05,  2.88it/s]\u001b[A\r\n",
      " 50%|█████████████████████▌                     | 16/32 [00:05<00:05,  2.88it/s]\u001b[A\r\n",
      " 53%|██████████████████████▊                    | 17/32 [00:05<00:05,  2.87it/s]\u001b[A\r\n",
      " 56%|████████████████████████▏                  | 18/32 [00:05<00:04,  2.87it/s]\u001b[A\r\n",
      " 59%|█████████████████████████▌                 | 19/32 [00:06<00:04,  2.88it/s]\u001b[A\r\n",
      " 62%|██████████████████████████▉                | 20/32 [00:06<00:04,  2.88it/s]\u001b[A\r\n",
      " 66%|████████████████████████████▏              | 21/32 [00:06<00:03,  2.85it/s]\u001b[A\r\n",
      " 69%|█████████████████████████████▌             | 22/32 [00:07<00:03,  2.82it/s]\u001b[A\r\n",
      " 72%|██████████████████████████████▉            | 23/32 [00:07<00:03,  2.83it/s]\u001b[A\r\n",
      " 75%|████████████████████████████████▎          | 24/32 [00:08<00:02,  2.84it/s]\u001b[A\r\n",
      " 78%|█████████████████████████████████▌         | 25/32 [00:08<00:02,  2.85it/s]\u001b[A\r\n",
      " 81%|██████████████████████████████████▉        | 26/32 [00:08<00:02,  2.86it/s]\u001b[A\r\n",
      " 84%|████████████████████████████████████▎      | 27/32 [00:09<00:01,  2.87it/s]\u001b[A\r\n",
      " 88%|█████████████████████████████████████▋     | 28/32 [00:09<00:01,  2.87it/s]\u001b[A\r\n",
      " 91%|██████████████████████████████████████▉    | 29/32 [00:09<00:01,  2.88it/s]\u001b[A\r\n",
      " 94%|████████████████████████████████████████▎  | 30/32 [00:10<00:00,  2.87it/s]\u001b[A\r\n",
      " 97%|█████████████████████████████████████████▋ | 31/32 [00:10<00:00,  2.91it/s]\u001b[A\r\n",
      "100%|███████████████████████████████████████████| 32/32 [00:10<00:00,  3.58it/s]\u001b[A\r\n",
      "\r\n",
      "Downloading builder script: 100%|██████████| 4.20k/4.20k [00:00<00:00, 14.8MB/s]\r\n",
      "Accuracy: {'accuracy': 0.76}\r\n",
      "\r\n",
      "\u001b[A{'eval_loss': 0.6929537057876587, 'eval_accuracy': 0.76, 'eval_runtime': 11.4959, 'eval_samples_per_second': 43.494, 'eval_steps_per_second': 2.784, 'epoch': 1.0}\r\n",
      " 10%|████                                    | 620/6200 [06:35<54:21,  1.71it/s]\r\n",
      "100%|███████████████████████████████████████████| 32/32 [00:11<00:00,  3.58it/s]\u001b[A\r\n",
      "                                                                                \u001b[A/opt/conda/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\r\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\r\n",
      "{'loss': 0.4796, 'learning_rate': 4.1935483870967746e-05, 'epoch': 1.61}\r\n",
      " 20%|███████▊                               | 1240/6200 [13:04<48:24,  1.71it/s]\r\n",
      "  0%|                                                    | 0/32 [00:00<?, ?it/s]\u001b[A\r\n",
      "  6%|██▊                                         | 2/32 [00:00<00:05,  5.81it/s]\u001b[A\r\n",
      "  9%|████▏                                       | 3/32 [00:00<00:07,  4.06it/s]\u001b[A\r\n",
      " 12%|█████▌                                      | 4/32 [00:01<00:07,  3.52it/s]\u001b[A\r\n",
      " 16%|██████▉                                     | 5/32 [00:01<00:08,  3.26it/s]\u001b[A\r\n",
      " 19%|████████▎                                   | 6/32 [00:01<00:08,  3.12it/s]\u001b[A\r\n",
      " 22%|█████████▋                                  | 7/32 [00:02<00:08,  3.04it/s]\u001b[A\r\n",
      " 25%|███████████                                 | 8/32 [00:02<00:08,  2.99it/s]\u001b[A\r\n",
      " 28%|████████████▍                               | 9/32 [00:02<00:07,  2.95it/s]\u001b[A\r\n",
      " 31%|█████████████▍                             | 10/32 [00:03<00:07,  2.93it/s]\u001b[A\r\n",
      " 34%|██████████████▊                            | 11/32 [00:03<00:07,  2.91it/s]\u001b[A\r\n",
      " 38%|████████████████▏                          | 12/32 [00:03<00:06,  2.90it/s]\u001b[A\r\n",
      " 41%|█████████████████▍                         | 13/32 [00:04<00:06,  2.89it/s]\u001b[A\r\n",
      " 44%|██████████████████▊                        | 14/32 [00:04<00:06,  2.88it/s]\u001b[A\r\n",
      " 47%|████████████████████▏                      | 15/32 [00:04<00:05,  2.87it/s]\u001b[A\r\n",
      " 50%|█████████████████████▌                     | 16/32 [00:05<00:05,  2.87it/s]\u001b[A\r\n",
      " 53%|██████████████████████▊                    | 17/32 [00:05<00:05,  2.87it/s]\u001b[A\r\n",
      " 56%|████████████████████████▏                  | 18/32 [00:05<00:04,  2.87it/s]\u001b[A\r\n",
      " 59%|█████████████████████████▌                 | 19/32 [00:06<00:04,  2.88it/s]\u001b[A\r\n",
      " 62%|██████████████████████████▉                | 20/32 [00:06<00:04,  2.87it/s]\u001b[A\r\n",
      " 66%|████████████████████████████▏              | 21/32 [00:06<00:03,  2.87it/s]\u001b[A\r\n",
      " 69%|█████████████████████████████▌             | 22/32 [00:07<00:03,  2.87it/s]\u001b[A\r\n",
      " 72%|██████████████████████████████▉            | 23/32 [00:07<00:03,  2.87it/s]\u001b[A\r\n",
      " 75%|████████████████████████████████▎          | 24/32 [00:08<00:02,  2.88it/s]\u001b[A\r\n",
      " 78%|█████████████████████████████████▌         | 25/32 [00:08<00:02,  2.87it/s]\u001b[A\r\n",
      " 81%|██████████████████████████████████▉        | 26/32 [00:08<00:02,  2.87it/s]\u001b[A\r\n",
      " 84%|████████████████████████████████████▎      | 27/32 [00:09<00:01,  2.87it/s]\u001b[A\r\n",
      " 88%|█████████████████████████████████████▋     | 28/32 [00:09<00:01,  2.87it/s]\u001b[A\r\n",
      " 91%|██████████████████████████████████████▉    | 29/32 [00:09<00:01,  2.87it/s]\u001b[A\r\n",
      " 94%|████████████████████████████████████████▎  | 30/32 [00:10<00:00,  2.87it/s]\u001b[A\r\n",
      " 97%|█████████████████████████████████████████▋ | 31/32 [00:10<00:00,  2.91it/s]\u001b[A\r\n",
      "100%|███████████████████████████████████████████| 32/32 [00:10<00:00,  3.58it/s]\u001b[AAccuracy: {'accuracy': 0.778}\r\n",
      "\r\n",
      "\u001b[A{'eval_loss': 1.0138498544692993, 'eval_accuracy': 0.778, 'eval_runtime': 11.3242, 'eval_samples_per_second': 44.153, 'eval_steps_per_second': 2.826, 'epoch': 2.0}\r\n",
      " 20%|███████▊                               | 1240/6200 [13:16<48:24,  1.71it/s]\r\n",
      "100%|███████████████████████████████████████████| 32/32 [00:10<00:00,  3.58it/s]\u001b[A\r\n",
      "                                                                                \u001b[A/opt/conda/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\r\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\r\n",
      "{'loss': 0.2879, 'learning_rate': 3.7903225806451614e-05, 'epoch': 2.42}\r\n",
      " 30%|███████████▋                           | 1860/6200 [19:44<42:27,  1.70it/s]\r\n",
      "  0%|                                                    | 0/32 [00:00<?, ?it/s]\u001b[A\r\n",
      "  6%|██▊                                         | 2/32 [00:00<00:05,  5.80it/s]\u001b[A\r\n",
      "  9%|████▏                                       | 3/32 [00:00<00:07,  4.04it/s]\u001b[A\r\n",
      " 12%|█████▌                                      | 4/32 [00:01<00:07,  3.50it/s]\u001b[A\r\n",
      " 16%|██████▉                                     | 5/32 [00:01<00:08,  3.25it/s]\u001b[A\r\n",
      " 19%|████████▎                                   | 6/32 [00:01<00:08,  3.11it/s]\u001b[A\r\n",
      " 22%|█████████▋                                  | 7/32 [00:02<00:08,  3.03it/s]\u001b[A\r\n",
      " 25%|███████████                                 | 8/32 [00:02<00:08,  2.99it/s]\u001b[A\r\n",
      " 28%|████████████▍                               | 9/32 [00:02<00:07,  2.96it/s]\u001b[A\r\n",
      " 31%|█████████████▍                             | 10/32 [00:03<00:07,  2.93it/s]\u001b[A\r\n",
      " 34%|██████████████▊                            | 11/32 [00:03<00:07,  2.91it/s]\u001b[A\r\n",
      " 38%|████████████████▏                          | 12/32 [00:03<00:06,  2.89it/s]\u001b[A\r\n",
      " 41%|█████████████████▍                         | 13/32 [00:04<00:06,  2.88it/s]\u001b[A\r\n",
      " 44%|██████████████████▊                        | 14/32 [00:04<00:06,  2.88it/s]\u001b[A\r\n",
      " 47%|████████████████████▏                      | 15/32 [00:05<00:07,  2.43it/s]\u001b[A\r\n",
      " 50%|█████████████████████▌                     | 16/32 [00:05<00:06,  2.55it/s]\u001b[A\r\n",
      " 53%|██████████████████████▊                    | 17/32 [00:05<00:05,  2.64it/s]\u001b[A\r\n",
      " 56%|████████████████████████▏                  | 18/32 [00:06<00:05,  2.71it/s]\u001b[A\r\n",
      " 59%|█████████████████████████▌                 | 19/32 [00:06<00:04,  2.76it/s]\u001b[A\r\n",
      " 62%|██████████████████████████▉                | 20/32 [00:06<00:04,  2.79it/s]\u001b[A\r\n",
      " 66%|████████████████████████████▏              | 21/32 [00:07<00:03,  2.81it/s]\u001b[A\r\n",
      " 69%|█████████████████████████████▌             | 22/32 [00:07<00:03,  2.83it/s]\u001b[A\r\n",
      " 72%|██████████████████████████████▉            | 23/32 [00:07<00:03,  2.84it/s]\u001b[A\r\n",
      " 75%|████████████████████████████████▎          | 24/32 [00:08<00:02,  2.86it/s]\u001b[A\r\n",
      " 78%|█████████████████████████████████▌         | 25/32 [00:08<00:02,  2.86it/s]\u001b[A\r\n",
      " 81%|██████████████████████████████████▉        | 26/32 [00:08<00:02,  2.86it/s]\u001b[A\r\n",
      " 84%|████████████████████████████████████▎      | 27/32 [00:09<00:01,  2.87it/s]\u001b[A\r\n",
      " 88%|█████████████████████████████████████▋     | 28/32 [00:09<00:01,  2.88it/s]\u001b[A\r\n",
      " 91%|██████████████████████████████████████▉    | 29/32 [00:09<00:01,  2.88it/s]\u001b[A\r\n",
      " 94%|████████████████████████████████████████▎  | 30/32 [00:10<00:00,  2.88it/s]\u001b[A\r\n",
      " 97%|█████████████████████████████████████████▋ | 31/32 [00:10<00:00,  2.92it/s]\u001b[A\r\n",
      "100%|███████████████████████████████████████████| 32/32 [00:10<00:00,  3.60it/s]\u001b[AAccuracy: {'accuracy': 0.766}\r\n",
      "\r\n",
      "\u001b[A{'eval_loss': 1.055943250656128, 'eval_accuracy': 0.766, 'eval_runtime': 11.557, 'eval_samples_per_second': 43.264, 'eval_steps_per_second': 2.769, 'epoch': 3.0}\r\n",
      " 30%|███████████▋                           | 1860/6200 [19:55<42:27,  1.70it/s]\r\n",
      "100%|███████████████████████████████████████████| 32/32 [00:11<00:00,  3.60it/s]\u001b[A\r\n",
      "                                                                                \u001b[A/opt/conda/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\r\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\r\n",
      "{'loss': 0.162, 'learning_rate': 3.387096774193548e-05, 'epoch': 3.23}\r\n",
      " 40%|███████████████▌                       | 2480/6200 [26:23<36:14,  1.71it/s]\r\n",
      "  0%|                                                    | 0/32 [00:00<?, ?it/s]\u001b[A\r\n",
      "  6%|██▊                                         | 2/32 [00:00<00:05,  5.77it/s]\u001b[A\r\n",
      "  9%|████▏                                       | 3/32 [00:00<00:07,  4.04it/s]\u001b[A\r\n",
      " 12%|█████▌                                      | 4/32 [00:01<00:07,  3.51it/s]\u001b[A\r\n",
      " 16%|██████▉                                     | 5/32 [00:01<00:08,  3.26it/s]\u001b[A\r\n",
      " 19%|████████▎                                   | 6/32 [00:01<00:08,  3.11it/s]\u001b[A\r\n",
      " 22%|█████████▋                                  | 7/32 [00:02<00:08,  3.03it/s]\u001b[A\r\n",
      " 25%|███████████                                 | 8/32 [00:02<00:08,  2.98it/s]\u001b[A\r\n",
      " 28%|████████████▍                               | 9/32 [00:02<00:07,  2.96it/s]\u001b[A\r\n",
      " 31%|█████████████▍                             | 10/32 [00:03<00:07,  2.92it/s]\u001b[A\r\n",
      " 34%|██████████████▊                            | 11/32 [00:03<00:07,  2.91it/s]\u001b[A\r\n",
      " 38%|████████████████▏                          | 12/32 [00:03<00:06,  2.89it/s]\u001b[A\r\n",
      " 41%|█████████████████▍                         | 13/32 [00:04<00:06,  2.88it/s]\u001b[A\r\n",
      " 44%|██████████████████▊                        | 14/32 [00:04<00:06,  2.88it/s]\u001b[A\r\n",
      " 47%|████████████████████▏                      | 15/32 [00:04<00:05,  2.88it/s]\u001b[A\r\n",
      " 50%|█████████████████████▌                     | 16/32 [00:05<00:05,  2.88it/s]\u001b[A\r\n",
      " 53%|██████████████████████▊                    | 17/32 [00:05<00:05,  2.88it/s]\u001b[A\r\n",
      " 56%|████████████████████████▏                  | 18/32 [00:05<00:04,  2.87it/s]\u001b[A\r\n",
      " 59%|█████████████████████████▌                 | 19/32 [00:06<00:04,  2.88it/s]\u001b[A\r\n",
      " 62%|██████████████████████████▉                | 20/32 [00:06<00:04,  2.87it/s]\u001b[A\r\n",
      " 66%|████████████████████████████▏              | 21/32 [00:06<00:03,  2.88it/s]\u001b[A\r\n",
      " 69%|█████████████████████████████▌             | 22/32 [00:07<00:04,  2.42it/s]\u001b[A\r\n",
      " 72%|██████████████████████████████▉            | 23/32 [00:07<00:03,  2.56it/s]\u001b[A\r\n",
      " 75%|████████████████████████████████▎          | 24/32 [00:08<00:03,  2.65it/s]\u001b[A\r\n",
      " 78%|█████████████████████████████████▌         | 25/32 [00:08<00:02,  2.72it/s]\u001b[A\r\n",
      " 81%|██████████████████████████████████▉        | 26/32 [00:08<00:02,  2.77it/s]\u001b[A\r\n",
      " 84%|████████████████████████████████████▎      | 27/32 [00:09<00:01,  2.80it/s]\u001b[A\r\n",
      " 88%|█████████████████████████████████████▋     | 28/32 [00:09<00:01,  2.82it/s]\u001b[A\r\n",
      " 91%|██████████████████████████████████████▉    | 29/32 [00:09<00:01,  2.84it/s]\u001b[A\r\n",
      " 94%|████████████████████████████████████████▎  | 30/32 [00:10<00:00,  2.85it/s]\u001b[A\r\n",
      " 97%|█████████████████████████████████████████▋ | 31/32 [00:10<00:00,  2.89it/s]\u001b[A\r\n",
      "100%|███████████████████████████████████████████| 32/32 [00:10<00:00,  3.56it/s]\u001b[AAccuracy: {'accuracy': 0.748}\r\n",
      "\r\n",
      "\u001b[A{'eval_loss': 1.837341547012329, 'eval_accuracy': 0.748, 'eval_runtime': 11.5165, 'eval_samples_per_second': 43.416, 'eval_steps_per_second': 2.779, 'epoch': 4.0}\r\n",
      " 40%|███████████████▌                       | 2480/6200 [26:35<36:14,  1.71it/s]\r\n",
      "100%|███████████████████████████████████████████| 32/32 [00:11<00:00,  3.56it/s]\u001b[A\r\n",
      "                                                                                \u001b[A/opt/conda/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\r\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\r\n",
      "{'loss': 0.0975, 'learning_rate': 2.9838709677419357e-05, 'epoch': 4.03}\r\n",
      "{'loss': 0.0438, 'learning_rate': 2.5806451612903226e-05, 'epoch': 4.84}\r\n",
      " 50%|███████████████████▌                   | 3100/6200 [33:03<30:13,  1.71it/s]\r\n",
      "  0%|                                                    | 0/32 [00:00<?, ?it/s]\u001b[A\r\n",
      "  6%|██▊                                         | 2/32 [00:00<00:05,  5.66it/s]\u001b[A\r\n",
      "  9%|████▏                                       | 3/32 [00:00<00:07,  4.01it/s]\u001b[A\r\n",
      " 12%|█████▌                                      | 4/32 [00:01<00:08,  3.49it/s]\u001b[A\r\n",
      " 16%|██████▉                                     | 5/32 [00:01<00:08,  3.24it/s]\u001b[A\r\n",
      " 19%|████████▎                                   | 6/32 [00:01<00:08,  3.10it/s]\u001b[A\r\n",
      " 22%|█████████▋                                  | 7/32 [00:02<00:08,  3.03it/s]\u001b[A\r\n",
      " 25%|███████████                                 | 8/32 [00:02<00:08,  2.97it/s]\u001b[A\r\n",
      " 28%|████████████▍                               | 9/32 [00:02<00:07,  2.94it/s]\u001b[A\r\n",
      " 31%|█████████████▍                             | 10/32 [00:03<00:07,  2.91it/s]\u001b[A\r\n",
      " 34%|██████████████▊                            | 11/32 [00:03<00:07,  2.90it/s]\u001b[A\r\n",
      " 38%|████████████████▏                          | 12/32 [00:03<00:06,  2.88it/s]\u001b[A\r\n",
      " 41%|█████████████████▍                         | 13/32 [00:04<00:06,  2.87it/s]\u001b[A\r\n",
      " 44%|██████████████████▊                        | 14/32 [00:04<00:06,  2.86it/s]\u001b[A\r\n",
      " 47%|████████████████████▏                      | 15/32 [00:04<00:05,  2.86it/s]\u001b[A\r\n",
      " 50%|█████████████████████▌                     | 16/32 [00:05<00:05,  2.87it/s]\u001b[A\r\n",
      " 53%|██████████████████████▊                    | 17/32 [00:05<00:05,  2.84it/s]\u001b[A\r\n",
      " 56%|████████████████████████▏                  | 18/32 [00:05<00:04,  2.82it/s]\u001b[A\r\n",
      " 59%|█████████████████████████▌                 | 19/32 [00:06<00:04,  2.81it/s]\u001b[A\r\n",
      " 62%|██████████████████████████▉                | 20/32 [00:06<00:04,  2.80it/s]\u001b[A\r\n",
      " 66%|████████████████████████████▏              | 21/32 [00:07<00:03,  2.82it/s]\u001b[A\r\n",
      " 69%|█████████████████████████████▌             | 22/32 [00:07<00:03,  2.83it/s]\u001b[A\r\n",
      " 72%|██████████████████████████████▉            | 23/32 [00:07<00:03,  2.85it/s]\u001b[A\r\n",
      " 75%|████████████████████████████████▎          | 24/32 [00:08<00:02,  2.86it/s]\u001b[A\r\n",
      " 78%|█████████████████████████████████▌         | 25/32 [00:08<00:02,  2.86it/s]\u001b[A\r\n",
      " 81%|██████████████████████████████████▉        | 26/32 [00:08<00:02,  2.86it/s]\u001b[A\r\n",
      " 84%|████████████████████████████████████▎      | 27/32 [00:09<00:01,  2.86it/s]\u001b[A\r\n",
      " 88%|█████████████████████████████████████▋     | 28/32 [00:09<00:01,  2.85it/s]\u001b[A\r\n",
      " 91%|██████████████████████████████████████▉    | 29/32 [00:09<00:01,  2.86it/s]\u001b[A\r\n",
      " 94%|████████████████████████████████████████▎  | 30/32 [00:10<00:00,  2.87it/s]\u001b[A\r\n",
      " 97%|█████████████████████████████████████████▋ | 31/32 [00:10<00:00,  2.45it/s]\u001b[A\r\n",
      "100%|███████████████████████████████████████████| 32/32 [00:10<00:00,  3.08it/s]\u001b[AAccuracy: {'accuracy': 0.774}\r\n",
      "\r\n",
      "\u001b[A{'eval_loss': 2.282012701034546, 'eval_accuracy': 0.774, 'eval_runtime': 11.8692, 'eval_samples_per_second': 42.126, 'eval_steps_per_second': 2.696, 'epoch': 5.0}\r\n",
      " 50%|███████████████████▌                   | 3100/6200 [33:14<30:13,  1.71it/s]\r\n",
      "100%|███████████████████████████████████████████| 32/32 [00:11<00:00,  3.08it/s]\u001b[A\r\n",
      "                                                                                \u001b[A/opt/conda/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\r\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\r\n",
      "{'loss': 0.0219, 'learning_rate': 2.1774193548387097e-05, 'epoch': 5.65}\r\n",
      " 60%|███████████████████████▍               | 3720/6200 [39:43<24:12,  1.71it/s]\r\n",
      "  0%|                                                    | 0/32 [00:00<?, ?it/s]\u001b[A\r\n",
      "  6%|██▊                                         | 2/32 [00:00<00:05,  5.75it/s]\u001b[A\r\n",
      "  9%|████▏                                       | 3/32 [00:00<00:07,  4.03it/s]\u001b[A\r\n",
      " 12%|█████▌                                      | 4/32 [00:01<00:07,  3.50it/s]\u001b[A\r\n",
      " 16%|██████▉                                     | 5/32 [00:01<00:08,  3.27it/s]\u001b[A\r\n",
      " 19%|████████▎                                   | 6/32 [00:01<00:08,  3.13it/s]\u001b[A\r\n",
      " 22%|█████████▋                                  | 7/32 [00:02<00:08,  3.05it/s]\u001b[A\r\n",
      " 25%|███████████                                 | 8/32 [00:02<00:08,  3.00it/s]\u001b[A\r\n",
      " 28%|████████████▍                               | 9/32 [00:02<00:07,  2.96it/s]\u001b[A\r\n",
      " 31%|█████████████▍                             | 10/32 [00:03<00:07,  2.94it/s]\u001b[A\r\n",
      " 34%|██████████████▊                            | 11/32 [00:03<00:07,  2.92it/s]\u001b[A\r\n",
      " 38%|████████████████▏                          | 12/32 [00:03<00:06,  2.90it/s]\u001b[A\r\n",
      " 41%|█████████████████▍                         | 13/32 [00:04<00:06,  2.89it/s]\u001b[A\r\n",
      " 44%|██████████████████▊                        | 14/32 [00:04<00:06,  2.88it/s]\u001b[A\r\n",
      " 47%|████████████████████▏                      | 15/32 [00:04<00:05,  2.87it/s]\u001b[A\r\n",
      " 50%|█████████████████████▌                     | 16/32 [00:05<00:05,  2.87it/s]\u001b[A\r\n",
      " 53%|██████████████████████▊                    | 17/32 [00:05<00:05,  2.86it/s]\u001b[A\r\n",
      " 56%|████████████████████████▏                  | 18/32 [00:05<00:04,  2.86it/s]\u001b[A\r\n",
      " 59%|█████████████████████████▌                 | 19/32 [00:06<00:04,  2.87it/s]\u001b[A\r\n",
      " 62%|██████████████████████████▉                | 20/32 [00:06<00:04,  2.86it/s]\u001b[A\r\n",
      " 66%|████████████████████████████▏              | 21/32 [00:06<00:03,  2.87it/s]\u001b[A\r\n",
      " 69%|█████████████████████████████▌             | 22/32 [00:07<00:03,  2.87it/s]\u001b[A\r\n",
      " 72%|██████████████████████████████▉            | 23/32 [00:07<00:03,  2.87it/s]\u001b[A\r\n",
      " 75%|████████████████████████████████▎          | 24/32 [00:08<00:02,  2.87it/s]\u001b[A\r\n",
      " 78%|█████████████████████████████████▌         | 25/32 [00:08<00:02,  2.87it/s]\u001b[A\r\n",
      " 81%|██████████████████████████████████▉        | 26/32 [00:08<00:02,  2.86it/s]\u001b[A\r\n",
      " 84%|████████████████████████████████████▎      | 27/32 [00:09<00:01,  2.86it/s]\u001b[A\r\n",
      " 88%|█████████████████████████████████████▋     | 28/32 [00:09<00:01,  2.86it/s]\u001b[A\r\n",
      " 91%|██████████████████████████████████████▉    | 29/32 [00:09<00:01,  2.86it/s]\u001b[A\r\n",
      " 94%|████████████████████████████████████████▎  | 30/32 [00:10<00:00,  2.86it/s]\u001b[A\r\n",
      " 97%|█████████████████████████████████████████▋ | 31/32 [00:10<00:00,  2.89it/s]\u001b[A\r\n",
      "100%|███████████████████████████████████████████| 32/32 [00:10<00:00,  3.56it/s]\u001b[AAccuracy: {'accuracy': 0.764}\r\n",
      "\r\n",
      "\u001b[A{'eval_loss': 2.372008800506592, 'eval_accuracy': 0.764, 'eval_runtime': 11.3658, 'eval_samples_per_second': 43.992, 'eval_steps_per_second': 2.815, 'epoch': 6.0}\r\n",
      " 60%|███████████████████████▍               | 3720/6200 [39:54<24:12,  1.71it/s]\r\n",
      "100%|███████████████████████████████████████████| 32/32 [00:10<00:00,  3.56it/s]\u001b[A\r\n",
      "                                                                                \u001b[A/opt/conda/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\r\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\r\n",
      "{'loss': 0.0288, 'learning_rate': 1.774193548387097e-05, 'epoch': 6.45}\r\n",
      " 70%|███████████████████████████▎           | 4340/6200 [46:21<18:05,  1.71it/s]\r\n",
      "  0%|                                                    | 0/32 [00:00<?, ?it/s]\u001b[A\r\n",
      "  6%|██▊                                         | 2/32 [00:00<00:05,  5.78it/s]\u001b[A\r\n",
      "  9%|████▏                                       | 3/32 [00:00<00:07,  4.01it/s]\u001b[A\r\n",
      " 12%|█████▌                                      | 4/32 [00:01<00:08,  3.48it/s]\u001b[A\r\n",
      " 16%|██████▉                                     | 5/32 [00:01<00:08,  3.25it/s]\u001b[A\r\n",
      " 19%|████████▎                                   | 6/32 [00:01<00:08,  3.11it/s]\u001b[A\r\n",
      " 22%|█████████▋                                  | 7/32 [00:02<00:08,  3.03it/s]\u001b[A\r\n",
      " 25%|███████████                                 | 8/32 [00:02<00:08,  2.98it/s]\u001b[A\r\n",
      " 28%|████████████▍                               | 9/32 [00:02<00:07,  2.95it/s]\u001b[A\r\n",
      " 31%|█████████████▍                             | 10/32 [00:03<00:07,  2.93it/s]\u001b[A\r\n",
      " 34%|██████████████▊                            | 11/32 [00:03<00:07,  2.91it/s]\u001b[A\r\n",
      " 38%|████████████████▏                          | 12/32 [00:03<00:06,  2.90it/s]\u001b[A\r\n",
      " 41%|█████████████████▍                         | 13/32 [00:04<00:06,  2.90it/s]\u001b[A\r\n",
      " 44%|██████████████████▊                        | 14/32 [00:04<00:06,  2.89it/s]\u001b[A\r\n",
      " 47%|████████████████████▏                      | 15/32 [00:04<00:05,  2.89it/s]\u001b[A\r\n",
      " 50%|█████████████████████▌                     | 16/32 [00:05<00:05,  2.89it/s]\u001b[A\r\n",
      " 53%|██████████████████████▊                    | 17/32 [00:05<00:05,  2.88it/s]\u001b[A\r\n",
      " 56%|████████████████████████▏                  | 18/32 [00:05<00:04,  2.88it/s]\u001b[A\r\n",
      " 59%|█████████████████████████▌                 | 19/32 [00:06<00:04,  2.88it/s]\u001b[A\r\n",
      " 62%|██████████████████████████▉                | 20/32 [00:06<00:04,  2.84it/s]\u001b[A\r\n",
      " 66%|████████████████████████████▏              | 21/32 [00:06<00:03,  2.86it/s]\u001b[A\r\n",
      " 69%|█████████████████████████████▌             | 22/32 [00:07<00:03,  2.86it/s]\u001b[A\r\n",
      " 72%|██████████████████████████████▉            | 23/32 [00:07<00:03,  2.85it/s]\u001b[A\r\n",
      " 75%|████████████████████████████████▎          | 24/32 [00:08<00:02,  2.86it/s]\u001b[A\r\n",
      " 78%|█████████████████████████████████▌         | 25/32 [00:08<00:02,  2.86it/s]\u001b[A\r\n",
      " 81%|██████████████████████████████████▉        | 26/32 [00:08<00:02,  2.87it/s]\u001b[A\r\n",
      " 84%|████████████████████████████████████▎      | 27/32 [00:09<00:01,  2.88it/s]\u001b[A\r\n",
      " 88%|█████████████████████████████████████▋     | 28/32 [00:09<00:01,  2.88it/s]\u001b[A\r\n",
      " 91%|██████████████████████████████████████▉    | 29/32 [00:09<00:01,  2.88it/s]\u001b[A\r\n",
      " 94%|████████████████████████████████████████▎  | 30/32 [00:10<00:00,  2.88it/s]\u001b[A\r\n",
      " 97%|█████████████████████████████████████████▋ | 31/32 [00:10<00:00,  2.91it/s]\u001b[A\r\n",
      "100%|███████████████████████████████████████████| 32/32 [00:10<00:00,  3.57it/s]\u001b[AAccuracy: {'accuracy': 0.782}\r\n",
      "\r\n",
      "\u001b[A{'eval_loss': 2.0667426586151123, 'eval_accuracy': 0.782, 'eval_runtime': 11.3779, 'eval_samples_per_second': 43.945, 'eval_steps_per_second': 2.812, 'epoch': 7.0}\r\n",
      " 70%|███████████████████████████▎           | 4340/6200 [46:33<18:05,  1.71it/s]\r\n",
      "100%|███████████████████████████████████████████| 32/32 [00:10<00:00,  3.57it/s]\u001b[A\r\n",
      "                                                                                \u001b[A/opt/conda/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\r\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\r\n",
      "{'loss': 0.0159, 'learning_rate': 1.3709677419354839e-05, 'epoch': 7.26}\r\n",
      " 80%|███████████████████████████████▏       | 4960/6200 [53:01<12:29,  1.65it/s]\r\n",
      "  0%|                                                    | 0/32 [00:00<?, ?it/s]\u001b[A\r\n",
      "  6%|██▊                                         | 2/32 [00:00<00:05,  5.81it/s]\u001b[A\r\n",
      "  9%|████▏                                       | 3/32 [00:00<00:07,  4.09it/s]\u001b[A\r\n",
      " 12%|█████▌                                      | 4/32 [00:01<00:07,  3.53it/s]\u001b[A\r\n",
      " 16%|██████▉                                     | 5/32 [00:01<00:08,  3.28it/s]\u001b[A\r\n",
      " 19%|████████▎                                   | 6/32 [00:01<00:08,  3.13it/s]\u001b[A\r\n",
      " 22%|█████████▋                                  | 7/32 [00:02<00:08,  3.02it/s]\u001b[A\r\n",
      " 25%|███████████                                 | 8/32 [00:02<00:08,  2.94it/s]\u001b[A\r\n",
      " 28%|████████████▍                               | 9/32 [00:02<00:07,  2.88it/s]\u001b[A\r\n",
      " 31%|█████████████▍                             | 10/32 [00:03<00:07,  2.87it/s]\u001b[A\r\n",
      " 34%|██████████████▊                            | 11/32 [00:03<00:07,  2.88it/s]\u001b[A\r\n",
      " 38%|████████████████▏                          | 12/32 [00:03<00:06,  2.88it/s]\u001b[A\r\n",
      " 41%|█████████████████▍                         | 13/32 [00:04<00:06,  2.88it/s]\u001b[A\r\n",
      " 44%|██████████████████▊                        | 14/32 [00:04<00:06,  2.88it/s]\u001b[A\r\n",
      " 47%|████████████████████▏                      | 15/32 [00:04<00:05,  2.88it/s]\u001b[A\r\n",
      " 50%|█████████████████████▌                     | 16/32 [00:05<00:05,  2.88it/s]\u001b[A\r\n",
      " 53%|██████████████████████▊                    | 17/32 [00:05<00:05,  2.88it/s]\u001b[A\r\n",
      " 56%|████████████████████████▏                  | 18/32 [00:05<00:04,  2.89it/s]\u001b[A\r\n",
      " 59%|█████████████████████████▌                 | 19/32 [00:06<00:04,  2.89it/s]\u001b[A\r\n",
      " 62%|██████████████████████████▉                | 20/32 [00:06<00:04,  2.89it/s]\u001b[A\r\n",
      " 66%|████████████████████████████▏              | 21/32 [00:06<00:03,  2.87it/s]\u001b[A\r\n",
      " 69%|█████████████████████████████▌             | 22/32 [00:07<00:03,  2.87it/s]\u001b[A\r\n",
      " 72%|██████████████████████████████▉            | 23/32 [00:07<00:03,  2.87it/s]\u001b[A\r\n",
      " 75%|████████████████████████████████▎          | 24/32 [00:08<00:02,  2.88it/s]\u001b[A\r\n",
      " 78%|█████████████████████████████████▌         | 25/32 [00:08<00:02,  2.88it/s]\u001b[A\r\n",
      " 81%|██████████████████████████████████▉        | 26/32 [00:08<00:02,  2.88it/s]\u001b[A\r\n",
      " 84%|████████████████████████████████████▎      | 27/32 [00:09<00:01,  2.87it/s]\u001b[A\r\n",
      " 88%|█████████████████████████████████████▋     | 28/32 [00:09<00:01,  2.86it/s]\u001b[A\r\n",
      " 91%|██████████████████████████████████████▉    | 29/32 [00:09<00:01,  2.87it/s]\u001b[A\r\n",
      " 94%|████████████████████████████████████████▎  | 30/32 [00:10<00:00,  2.88it/s]\u001b[A\r\n",
      " 97%|█████████████████████████████████████████▋ | 31/32 [00:10<00:00,  2.92it/s]\u001b[A\r\n",
      "100%|███████████████████████████████████████████| 32/32 [00:10<00:00,  3.59it/s]\u001b[AAccuracy: {'accuracy': 0.768}\r\n",
      "\r\n",
      "\u001b[A{'eval_loss': 2.488166570663452, 'eval_accuracy': 0.768, 'eval_runtime': 11.4457, 'eval_samples_per_second': 43.684, 'eval_steps_per_second': 2.796, 'epoch': 8.0}\r\n",
      " 80%|███████████████████████████████▏       | 4960/6200 [53:13<12:29,  1.65it/s]\r\n",
      "100%|███████████████████████████████████████████| 32/32 [00:11<00:00,  3.59it/s]\u001b[A\r\n",
      "                                                                                \u001b[A/opt/conda/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\r\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\r\n",
      "{'loss': 0.0149, 'learning_rate': 9.67741935483871e-06, 'epoch': 8.06}\r\n",
      "{'loss': 0.0067, 'learning_rate': 5.64516129032258e-06, 'epoch': 8.87}\r\n",
      " 90%|███████████████████████████████████    | 5580/6200 [59:39<06:01,  1.71it/s]\r\n",
      "  0%|                                                    | 0/32 [00:00<?, ?it/s]\u001b[A\r\n",
      "  6%|██▊                                         | 2/32 [00:00<00:05,  5.83it/s]\u001b[A\r\n",
      "  9%|████▏                                       | 3/32 [00:00<00:07,  4.06it/s]\u001b[A\r\n",
      " 12%|█████▌                                      | 4/32 [00:01<00:07,  3.52it/s]\u001b[A\r\n",
      " 16%|██████▉                                     | 5/32 [00:01<00:08,  3.27it/s]\u001b[A\r\n",
      " 19%|████████▎                                   | 6/32 [00:01<00:08,  3.13it/s]\u001b[A\r\n",
      " 22%|█████████▋                                  | 7/32 [00:02<00:08,  3.04it/s]\u001b[A\r\n",
      " 25%|███████████                                 | 8/32 [00:02<00:08,  2.99it/s]\u001b[A\r\n",
      " 28%|████████████▍                               | 9/32 [00:02<00:07,  2.96it/s]\u001b[A\r\n",
      " 31%|█████████████▍                             | 10/32 [00:03<00:07,  2.93it/s]\u001b[A\r\n",
      " 34%|██████████████▊                            | 11/32 [00:03<00:07,  2.92it/s]\u001b[A\r\n",
      " 38%|████████████████▏                          | 12/32 [00:03<00:06,  2.90it/s]\u001b[A\r\n",
      " 41%|█████████████████▍                         | 13/32 [00:04<00:06,  2.89it/s]\u001b[A\r\n",
      " 44%|██████████████████▊                        | 14/32 [00:04<00:06,  2.88it/s]\u001b[A\r\n",
      " 47%|████████████████████▏                      | 15/32 [00:04<00:05,  2.87it/s]\u001b[A\r\n",
      " 50%|█████████████████████▌                     | 16/32 [00:05<00:05,  2.87it/s]\u001b[A\r\n",
      " 53%|██████████████████████▊                    | 17/32 [00:05<00:05,  2.87it/s]\u001b[A\r\n",
      " 56%|████████████████████████▏                  | 18/32 [00:05<00:04,  2.87it/s]\u001b[A\r\n",
      " 59%|█████████████████████████▌                 | 19/32 [00:06<00:04,  2.88it/s]\u001b[A\r\n",
      " 62%|██████████████████████████▉                | 20/32 [00:06<00:04,  2.87it/s]\u001b[A\r\n",
      " 66%|████████████████████████████▏              | 21/32 [00:06<00:03,  2.87it/s]\u001b[A\r\n",
      " 69%|█████████████████████████████▌             | 22/32 [00:07<00:03,  2.87it/s]\u001b[A\r\n",
      " 72%|██████████████████████████████▉            | 23/32 [00:07<00:03,  2.88it/s]\u001b[A\r\n",
      " 75%|████████████████████████████████▎          | 24/32 [00:07<00:02,  2.88it/s]\u001b[A\r\n",
      " 78%|█████████████████████████████████▌         | 25/32 [00:08<00:02,  2.88it/s]\u001b[A\r\n",
      " 81%|██████████████████████████████████▉        | 26/32 [00:08<00:02,  2.88it/s]\u001b[A\r\n",
      " 84%|████████████████████████████████████▎      | 27/32 [00:09<00:01,  2.88it/s]\u001b[A\r\n",
      " 88%|█████████████████████████████████████▋     | 28/32 [00:09<00:01,  2.88it/s]\u001b[A\r\n",
      " 91%|██████████████████████████████████████▉    | 29/32 [00:09<00:01,  2.88it/s]\u001b[A\r\n",
      " 94%|████████████████████████████████████████▎  | 30/32 [00:10<00:00,  2.88it/s]\u001b[A\r\n",
      " 97%|█████████████████████████████████████████▋ | 31/32 [00:10<00:00,  2.92it/s]\u001b[A\r\n",
      "100%|███████████████████████████████████████████| 32/32 [00:10<00:00,  3.58it/s]\u001b[AAccuracy: {'accuracy': 0.774}\r\n",
      "\r\n",
      "\u001b[A{'eval_loss': 2.437147378921509, 'eval_accuracy': 0.774, 'eval_runtime': 11.3278, 'eval_samples_per_second': 44.139, 'eval_steps_per_second': 2.825, 'epoch': 9.0}\r\n",
      " 90%|███████████████████████████████████    | 5580/6200 [59:51<06:01,  1.71it/s]\r\n",
      "100%|███████████████████████████████████████████| 32/32 [00:10<00:00,  3.58it/s]\u001b[A\r\n",
      "                                                                                \u001b[A/opt/conda/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\r\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\r\n",
      "{'loss': 0.0064, 'learning_rate': 1.6129032258064516e-06, 'epoch': 9.68}\r\n",
      "100%|█████████████████████████████████████| 6200/6200 [1:06:19<00:00,  1.72it/s]\r\n",
      "  0%|                                                    | 0/32 [00:00<?, ?it/s]\u001b[A\r\n",
      "  6%|██▊                                         | 2/32 [00:00<00:05,  5.80it/s]\u001b[A\r\n",
      "  9%|████▏                                       | 3/32 [00:00<00:07,  4.08it/s]\u001b[A\r\n",
      " 12%|█████▌                                      | 4/32 [00:01<00:07,  3.54it/s]\u001b[A\r\n",
      " 16%|██████▉                                     | 5/32 [00:01<00:08,  3.28it/s]\u001b[A\r\n",
      " 19%|████████▎                                   | 6/32 [00:01<00:08,  3.13it/s]\u001b[A\r\n",
      " 22%|█████████▋                                  | 7/32 [00:02<00:08,  3.05it/s]\u001b[A\r\n",
      " 25%|███████████                                 | 8/32 [00:02<00:08,  2.99it/s]\u001b[A\r\n",
      " 28%|████████████▍                               | 9/32 [00:02<00:07,  2.96it/s]\u001b[A\r\n",
      " 31%|█████████████▍                             | 10/32 [00:03<00:07,  2.94it/s]\u001b[A\r\n",
      " 34%|██████████████▊                            | 11/32 [00:03<00:07,  2.91it/s]\u001b[A\r\n",
      " 38%|████████████████▏                          | 12/32 [00:03<00:06,  2.89it/s]\u001b[A\r\n",
      " 41%|█████████████████▍                         | 13/32 [00:04<00:06,  2.88it/s]\u001b[A\r\n",
      " 44%|██████████████████▊                        | 14/32 [00:04<00:06,  2.89it/s]\u001b[A\r\n",
      " 47%|████████████████████▏                      | 15/32 [00:04<00:05,  2.89it/s]\u001b[A\r\n",
      " 50%|█████████████████████▌                     | 16/32 [00:05<00:05,  2.88it/s]\u001b[A\r\n",
      " 53%|██████████████████████▊                    | 17/32 [00:05<00:05,  2.88it/s]\u001b[A\r\n",
      " 56%|████████████████████████▏                  | 18/32 [00:05<00:04,  2.88it/s]\u001b[A\r\n",
      " 59%|█████████████████████████▌                 | 19/32 [00:06<00:04,  2.88it/s]\u001b[A\r\n",
      " 62%|██████████████████████████▉                | 20/32 [00:06<00:04,  2.88it/s]\u001b[A\r\n",
      " 66%|████████████████████████████▏              | 21/32 [00:06<00:03,  2.87it/s]\u001b[A\r\n",
      " 69%|█████████████████████████████▌             | 22/32 [00:07<00:03,  2.88it/s]\u001b[A\r\n",
      " 72%|██████████████████████████████▉            | 23/32 [00:07<00:03,  2.88it/s]\u001b[A\r\n",
      " 75%|████████████████████████████████▎          | 24/32 [00:07<00:02,  2.89it/s]\u001b[A\r\n",
      " 78%|█████████████████████████████████▌         | 25/32 [00:08<00:02,  2.88it/s]\u001b[A\r\n",
      " 81%|██████████████████████████████████▉        | 26/32 [00:08<00:02,  2.89it/s]\u001b[A\r\n",
      " 84%|████████████████████████████████████▎      | 27/32 [00:09<00:01,  2.89it/s]\u001b[A\r\n",
      " 88%|█████████████████████████████████████▋     | 28/32 [00:09<00:01,  2.87it/s]\u001b[A\r\n",
      " 91%|██████████████████████████████████████▉    | 29/32 [00:09<00:01,  2.88it/s]\u001b[A\r\n",
      " 94%|████████████████████████████████████████▎  | 30/32 [00:10<00:00,  2.88it/s]\u001b[A\r\n",
      " 97%|█████████████████████████████████████████▋ | 31/32 [00:10<00:00,  2.92it/s]\u001b[A\r\n",
      "100%|███████████████████████████████████████████| 32/32 [00:10<00:00,  3.59it/s]\u001b[AAccuracy: {'accuracy': 0.772}\r\n",
      "\r\n",
      "\u001b[A{'eval_loss': 2.301961898803711, 'eval_accuracy': 0.772, 'eval_runtime': 11.2736, 'eval_samples_per_second': 44.351, 'eval_steps_per_second': 2.838, 'epoch': 10.0}\r\n",
      "100%|█████████████████████████████████████| 6200/6200 [1:06:30<00:00,  1.72it/s]\r\n",
      "100%|███████████████████████████████████████████| 32/32 [00:10<00:00,  3.59it/s]\u001b[A\r\n",
      "{'train_runtime': 3994.7164, 'train_samples_per_second': 12.409, 'train_steps_per_second': 1.552, 'train_loss': 0.1646562990642363, 'epoch': 10.0}\r\n",
      "100%|█████████████████████████████████████| 6200/6200 [1:06:34<00:00,  1.55it/s]\r\n",
      "/opt/conda/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\r\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\r\n",
      "100%|███████████████████████████████████████████| 32/32 [00:10<00:00,  3.58it/s]Accuracy: {'accuracy': 0.772}\r\n",
      "100%|███████████████████████████████████████████| 32/32 [00:10<00:00,  2.95it/s]\r\n",
      "/opt/conda/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\r\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\r\n",
      "100%|███████████████████████████████████████████| 32/32 [00:10<00:00,  2.84it/s]Accuracy: {'accuracy': 0.752}\r\n",
      "100%|███████████████████████████████████████████| 32/32 [00:11<00:00,  2.85it/s]\r\n"
     ]
    }
   ],
   "source": [
    "!CUDA_VISIBLE_DEVICES=0,1 python train.py --output_dir checkpoints/deberta_obqa_usebook_noclues_10 --num_train_epochs 10 --use_book True --n_facts 1 --report_to=\"none\" --do_train --do_eval --per_device_train_batch_size 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "959df609",
   "metadata": {
    "papermill": {
     "duration": 0.525529,
     "end_time": "2024-03-10T20:03:10.364302",
     "exception": false,
     "start_time": "2024-03-10T20:03:09.838773",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "nvidiaTeslaT4",
   "dataSources": [
    {
     "datasetId": 4529429,
     "sourceId": 7747977,
     "sourceType": "datasetVersion"
    }
   ],
   "dockerImageVersionId": 30648,
   "isGpuEnabled": true,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 4082.488328,
   "end_time": "2024-03-10T20:03:11.623865",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2024-03-10T18:55:09.135537",
   "version": "2.5.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
