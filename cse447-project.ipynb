{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"gpu","dataSources":[],"dockerImageVersionId":30648,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2024-02-11T17:06:17.183651Z","iopub.execute_input":"2024-02-11T17:06:17.183941Z","iopub.status.idle":"2024-02-11T17:06:18.187528Z","shell.execute_reply.started":"2024-02-11T17:06:17.183915Z","shell.execute_reply":"2024-02-11T17:06:18.186172Z"},"trusted":true},"execution_count":1,"outputs":[]},{"cell_type":"code","source":"!git clone https://github.com/PopoDev/CSE447_Project.git","metadata":{"execution":{"iopub.status.busy":"2024-02-11T17:06:18.190052Z","iopub.execute_input":"2024-02-11T17:06:18.192877Z","iopub.status.idle":"2024-02-11T17:06:21.653783Z","shell.execute_reply.started":"2024-02-11T17:06:18.192830Z","shell.execute_reply":"2024-02-11T17:06:21.652528Z"},"trusted":true},"execution_count":2,"outputs":[{"name":"stdout","text":"Cloning into 'CSE447_Project'...\nremote: Enumerating objects: 35, done.\u001b[K\nremote: Counting objects: 100% (35/35), done.\u001b[K\nremote: Compressing objects: 100% (26/26), done.\u001b[K\nremote: Total 35 (delta 9), reused 29 (delta 6), pack-reused 0\u001b[K\nUnpacking objects: 100% (35/35), 9.77 MiB | 5.83 MiB/s, done.\n","output_type":"stream"}]},{"cell_type":"code","source":"ls","metadata":{"execution":{"iopub.status.busy":"2024-02-11T17:06:21.655439Z","iopub.execute_input":"2024-02-11T17:06:21.655831Z","iopub.status.idle":"2024-02-11T17:06:22.612642Z","shell.execute_reply.started":"2024-02-11T17:06:21.655792Z","shell.execute_reply":"2024-02-11T17:06:22.611650Z"},"trusted":true},"execution_count":3,"outputs":[{"name":"stdout","text":"\u001b[0m\u001b[01;34mCSE447_Project\u001b[0m/\n","output_type":"stream"}]},{"cell_type":"code","source":"cd CSE447_Project/","metadata":{"execution":{"iopub.status.busy":"2024-02-11T17:06:22.615101Z","iopub.execute_input":"2024-02-11T17:06:22.615419Z","iopub.status.idle":"2024-02-11T17:06:22.622638Z","shell.execute_reply.started":"2024-02-11T17:06:22.615389Z","shell.execute_reply":"2024-02-11T17:06:22.621711Z"},"trusted":true},"execution_count":4,"outputs":[{"name":"stdout","text":"/kaggle/working/CSE447_Project\n","output_type":"stream"}]},{"cell_type":"markdown","source":"# GenMC","metadata":{}},{"cell_type":"code","source":"cd GenMC/","metadata":{"execution":{"iopub.status.busy":"2024-02-11T17:06:22.623989Z","iopub.execute_input":"2024-02-11T17:06:22.624261Z","iopub.status.idle":"2024-02-11T17:06:22.633676Z","shell.execute_reply.started":"2024-02-11T17:06:22.624237Z","shell.execute_reply":"2024-02-11T17:06:22.632849Z"},"trusted":true},"execution_count":5,"outputs":[{"name":"stdout","text":"/kaggle/working/CSE447_Project/GenMC\n","output_type":"stream"}]},{"cell_type":"code","source":"ls","metadata":{"execution":{"iopub.status.busy":"2024-02-11T17:06:22.634788Z","iopub.execute_input":"2024-02-11T17:06:22.635503Z","iopub.status.idle":"2024-02-11T17:06:23.587964Z","shell.execute_reply.started":"2024-02-11T17:06:22.635478Z","shell.execute_reply":"2024-02-11T17:06:23.587067Z"},"trusted":true},"execution_count":6,"outputs":[{"name":"stdout","text":"\u001b[0m\u001b[01;34mdata\u001b[0m/  \u001b[01;34mmodel\u001b[0m/  requirements.txt  run_genmc.py  utils.py\n","output_type":"stream"}]},{"cell_type":"code","source":"!pip install -r requirements.txt","metadata":{"execution":{"iopub.status.busy":"2024-02-11T17:06:23.589677Z","iopub.execute_input":"2024-02-11T17:06:23.590505Z","iopub.status.idle":"2024-02-11T17:07:06.673760Z","shell.execute_reply.started":"2024-02-11T17:06:23.590467Z","shell.execute_reply":"2024-02-11T17:07:06.672711Z"},"trusted":true},"execution_count":7,"outputs":[{"name":"stdout","text":"Collecting apex==0.9.10dev (from -r requirements.txt (line 1))\n  Downloading apex-0.9.10dev.tar.gz (36 kB)\n  Preparing metadata (setup.py) ... \u001b[?25ldone\n\u001b[?25hRequirement already satisfied: numpy==1.24.4 in /opt/conda/lib/python3.10/site-packages (from -r requirements.txt (line 2)) (1.24.4)\nCollecting rouge==1.0.1 (from -r requirements.txt (line 3))\n  Downloading rouge-1.0.1-py3-none-any.whl (13 kB)\nRequirement already satisfied: torch==2.1.2 in /opt/conda/lib/python3.10/site-packages (from -r requirements.txt (line 4)) (2.1.2)\nRequirement already satisfied: tqdm==4.66.1 in /opt/conda/lib/python3.10/site-packages (from -r requirements.txt (line 5)) (4.66.1)\nRequirement already satisfied: transformers==4.37.0 in /opt/conda/lib/python3.10/site-packages (from -r requirements.txt (line 6)) (4.37.0)\nCollecting cryptacular (from apex==0.9.10dev->-r requirements.txt (line 1))\n  Downloading cryptacular-1.6.2.tar.gz (75 kB)\n\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m75.8/75.8 kB\u001b[0m \u001b[31m3.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25h  Installing build dependencies ... \u001b[?25ldone\n\u001b[?25h  Getting requirements to build wheel ... \u001b[?25ldone\n\u001b[?25h  Preparing metadata (pyproject.toml) ... \u001b[?25ldone\n\u001b[?25hCollecting zope.sqlalchemy (from apex==0.9.10dev->-r requirements.txt (line 1))\n  Downloading zope.sqlalchemy-3.1-py3-none-any.whl.metadata (18 kB)\nCollecting velruse>=1.0.3 (from apex==0.9.10dev->-r requirements.txt (line 1))\n  Downloading velruse-1.1.1.tar.gz (709 kB)\n\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m709.8/709.8 kB\u001b[0m \u001b[31m18.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m\n\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25ldone\n\u001b[?25hCollecting pyramid>1.1.2 (from apex==0.9.10dev->-r requirements.txt (line 1))\n  Downloading pyramid-2.0.2-py3-none-any.whl.metadata (20 kB)\nCollecting pyramid_mailer (from apex==0.9.10dev->-r requirements.txt (line 1))\n  Downloading pyramid_mailer-0.15.1-py2.py3-none-any.whl (19 kB)\nRequirement already satisfied: requests in /opt/conda/lib/python3.10/site-packages (from apex==0.9.10dev->-r requirements.txt (line 1)) (2.31.0)\nCollecting wtforms (from apex==0.9.10dev->-r requirements.txt (line 1))\n  Downloading wtforms-3.1.2-py3-none-any.whl.metadata (5.3 kB)\nCollecting wtforms-recaptcha (from apex==0.9.10dev->-r requirements.txt (line 1))\n  Downloading wtforms_recaptcha-0.3.2-py2.py3-none-any.whl (7.5 kB)\nRequirement already satisfied: six in /opt/conda/lib/python3.10/site-packages (from rouge==1.0.1->-r requirements.txt (line 3)) (1.16.0)\nRequirement already satisfied: filelock in /opt/conda/lib/python3.10/site-packages (from torch==2.1.2->-r requirements.txt (line 4)) (3.13.1)\nRequirement already satisfied: typing-extensions in /opt/conda/lib/python3.10/site-packages (from torch==2.1.2->-r requirements.txt (line 4)) (4.9.0)\nRequirement already satisfied: sympy in /opt/conda/lib/python3.10/site-packages (from torch==2.1.2->-r requirements.txt (line 4)) (1.12)\nRequirement already satisfied: networkx in /opt/conda/lib/python3.10/site-packages (from torch==2.1.2->-r requirements.txt (line 4)) (3.2.1)\nRequirement already satisfied: jinja2 in /opt/conda/lib/python3.10/site-packages (from torch==2.1.2->-r requirements.txt (line 4)) (3.1.2)\nRequirement already satisfied: fsspec in /opt/conda/lib/python3.10/site-packages (from torch==2.1.2->-r requirements.txt (line 4)) (2023.12.2)\nRequirement already satisfied: huggingface-hub<1.0,>=0.19.3 in /opt/conda/lib/python3.10/site-packages (from transformers==4.37.0->-r requirements.txt (line 6)) (0.20.3)\nRequirement already satisfied: packaging>=20.0 in /opt/conda/lib/python3.10/site-packages (from transformers==4.37.0->-r requirements.txt (line 6)) (21.3)\nRequirement already satisfied: pyyaml>=5.1 in /opt/conda/lib/python3.10/site-packages (from transformers==4.37.0->-r requirements.txt (line 6)) (6.0.1)\nRequirement already satisfied: regex!=2019.12.17 in /opt/conda/lib/python3.10/site-packages (from transformers==4.37.0->-r requirements.txt (line 6)) (2023.12.25)\nRequirement already satisfied: tokenizers<0.19,>=0.14 in /opt/conda/lib/python3.10/site-packages (from transformers==4.37.0->-r requirements.txt (line 6)) (0.15.1)\nRequirement already satisfied: safetensors>=0.3.1 in /opt/conda/lib/python3.10/site-packages (from transformers==4.37.0->-r requirements.txt (line 6)) (0.4.2)\nRequirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /opt/conda/lib/python3.10/site-packages (from packaging>=20.0->transformers==4.37.0->-r requirements.txt (line 6)) (3.1.1)\nCollecting hupper>=1.5 (from pyramid>1.1.2->apex==0.9.10dev->-r requirements.txt (line 1))\n  Downloading hupper-1.12.1-py3-none-any.whl.metadata (3.7 kB)\nCollecting plaster (from pyramid>1.1.2->apex==0.9.10dev->-r requirements.txt (line 1))\n  Downloading plaster-1.1.2-py2.py3-none-any.whl (11 kB)\nCollecting plaster-pastedeploy (from pyramid>1.1.2->apex==0.9.10dev->-r requirements.txt (line 1))\n  Downloading plaster_pastedeploy-1.0.1-py2.py3-none-any.whl (7.8 kB)\nRequirement already satisfied: setuptools in /opt/conda/lib/python3.10/site-packages (from pyramid>1.1.2->apex==0.9.10dev->-r requirements.txt (line 1)) (69.0.3)\nCollecting translationstring>=0.4 (from pyramid>1.1.2->apex==0.9.10dev->-r requirements.txt (line 1))\n  Downloading translationstring-1.4-py2.py3-none-any.whl (15 kB)\nCollecting venusian>=1.0 (from pyramid>1.1.2->apex==0.9.10dev->-r requirements.txt (line 1))\n  Downloading venusian-3.1.0-py3-none-any.whl.metadata (10 kB)\nCollecting webob>=1.8.3 (from pyramid>1.1.2->apex==0.9.10dev->-r requirements.txt (line 1))\n  Downloading WebOb-1.8.7-py2.py3-none-any.whl (114 kB)\n\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m115.0/115.0 kB\u001b[0m \u001b[31m7.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hCollecting zope.deprecation>=3.5.0 (from pyramid>1.1.2->apex==0.9.10dev->-r requirements.txt (line 1))\n  Downloading zope.deprecation-5.0-py3-none-any.whl (10 kB)\nCollecting zope.interface>=3.8.0 (from pyramid>1.1.2->apex==0.9.10dev->-r requirements.txt (line 1))\n  Downloading zope.interface-6.1-cp310-cp310-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (41 kB)\n\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m41.7/41.7 kB\u001b[0m \u001b[31m2.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hRequirement already satisfied: requests-oauthlib in /opt/conda/lib/python3.10/site-packages (from velruse>=1.0.3->apex==0.9.10dev->-r requirements.txt (line 1)) (1.3.1)\nCollecting anykeystore (from velruse>=1.0.3->apex==0.9.10dev->-r requirements.txt (line 1))\n  Downloading anykeystore-0.2.tar.gz (10 kB)\n  Preparing metadata (setup.py) ... \u001b[?25ldone\n\u001b[?25hCollecting python3-openid (from velruse>=1.0.3->apex==0.9.10dev->-r requirements.txt (line 1))\n  Downloading python3_openid-3.2.0-py3-none-any.whl (133 kB)\n\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m133.7/133.7 kB\u001b[0m \u001b[31m9.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hCollecting pbkdf2 (from cryptacular->apex==0.9.10dev->-r requirements.txt (line 1))\n  Downloading pbkdf2-1.3.tar.gz (6.4 kB)\n  Preparing metadata (setup.py) ... \u001b[?25ldone\n\u001b[?25hRequirement already satisfied: MarkupSafe>=2.0 in /opt/conda/lib/python3.10/site-packages (from jinja2->torch==2.1.2->-r requirements.txt (line 4)) (2.1.3)\nCollecting repoze.sendmail>=4.1 (from pyramid_mailer->apex==0.9.10dev->-r requirements.txt (line 1))\n  Downloading repoze.sendmail-4.4.1-py2.py3-none-any.whl (41 kB)\n\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m41.0/41.0 kB\u001b[0m \u001b[31m2.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hCollecting transaction (from pyramid_mailer->apex==0.9.10dev->-r requirements.txt (line 1))\n  Downloading transaction-4.0-py3-none-any.whl.metadata (14 kB)\nRequirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.10/site-packages (from requests->apex==0.9.10dev->-r requirements.txt (line 1)) (3.3.2)\nRequirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.10/site-packages (from requests->apex==0.9.10dev->-r requirements.txt (line 1)) (3.6)\nRequirement already satisfied: urllib3<3,>=1.21.1 in /opt/conda/lib/python3.10/site-packages (from requests->apex==0.9.10dev->-r requirements.txt (line 1)) (1.26.18)\nRequirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.10/site-packages (from requests->apex==0.9.10dev->-r requirements.txt (line 1)) (2023.11.17)\nRequirement already satisfied: mpmath>=0.19 in /opt/conda/lib/python3.10/site-packages (from sympy->torch==2.1.2->-r requirements.txt (line 4)) (1.3.0)\nRequirement already satisfied: SQLAlchemy!=1.4.0,!=1.4.1,!=1.4.2,!=1.4.3,!=1.4.4,!=1.4.5,!=1.4.6,>=1.1 in /opt/conda/lib/python3.10/site-packages (from zope.sqlalchemy->apex==0.9.10dev->-r requirements.txt (line 1)) (2.0.25)\nRequirement already satisfied: greenlet!=0.4.17 in /opt/conda/lib/python3.10/site-packages (from SQLAlchemy!=1.4.0,!=1.4.1,!=1.4.2,!=1.4.3,!=1.4.4,!=1.4.5,!=1.4.6,>=1.1->zope.sqlalchemy->apex==0.9.10dev->-r requirements.txt (line 1)) (3.0.3)\nCollecting PasteDeploy>=2.0 (from plaster-pastedeploy->pyramid>1.1.2->apex==0.9.10dev->-r requirements.txt (line 1))\n  Downloading PasteDeploy-3.1.0-py3-none-any.whl.metadata (2.7 kB)\nRequirement already satisfied: defusedxml in /opt/conda/lib/python3.10/site-packages (from python3-openid->velruse>=1.0.3->apex==0.9.10dev->-r requirements.txt (line 1)) (0.7.1)\nRequirement already satisfied: oauthlib>=3.0.0 in /opt/conda/lib/python3.10/site-packages (from requests-oauthlib->velruse>=1.0.3->apex==0.9.10dev->-r requirements.txt (line 1)) (3.2.2)\nDownloading pyramid-2.0.2-py3-none-any.whl (247 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m247.3/247.3 kB\u001b[0m \u001b[31m14.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hDownloading wtforms-3.1.2-py3-none-any.whl (145 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m146.0/146.0 kB\u001b[0m \u001b[31m10.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hDownloading zope.sqlalchemy-3.1-py3-none-any.whl (23 kB)\nDownloading hupper-1.12.1-py3-none-any.whl (22 kB)\nDownloading transaction-4.0-py3-none-any.whl (46 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m46.6/46.6 kB\u001b[0m \u001b[31m3.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hDownloading venusian-3.1.0-py3-none-any.whl (13 kB)\nDownloading zope.interface-6.1-cp310-cp310-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (247 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m247.1/247.1 kB\u001b[0m \u001b[31m15.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hDownloading PasteDeploy-3.1.0-py3-none-any.whl (16 kB)\nBuilding wheels for collected packages: apex, velruse, cryptacular, anykeystore, pbkdf2\n  Building wheel for apex (setup.py) ... \u001b[?25ldone\n\u001b[?25h  Created wheel for apex: filename=apex-0.9.10.dev0-py3-none-any.whl size=46442 sha256=8561eb5301b09cb6c18cf1161b6e9d03dfd1d3aec65ace807845354b3c2b18a1\n  Stored in directory: /root/.cache/pip/wheels/6e/62/59/9b100fce7ebd989603b3b7a4ca259150da72c9e107fcaa2a30\n  Building wheel for velruse (setup.py) ... \u001b[?25ldone\n\u001b[?25h  Created wheel for velruse: filename=velruse-1.1.1-py3-none-any.whl size=50909 sha256=994b601d299270f724ad547f666d4d2d8802604362d3d668c1ee47b512eab2bc\n  Stored in directory: /root/.cache/pip/wheels/4a/f9/a4/fc4ea7b935ee9c58b9bc772cabd94f6a8560f35444097d948d\n  Building wheel for cryptacular (pyproject.toml) ... \u001b[?25ldone\n\u001b[?25h  Created wheel for cryptacular: filename=cryptacular-1.6.2-cp310-cp310-linux_x86_64.whl size=28236 sha256=4d3fb04ae517a062225502b03a6c285384e56234bcea260be4c453c092fdc86a\n  Stored in directory: /root/.cache/pip/wheels/3f/6e/09/a7fba517f95b2a6a36bd01b6d4f4679fa7259615a493b64b8f\n  Building wheel for anykeystore (setup.py) ... \u001b[?25ldone\n\u001b[?25h  Created wheel for anykeystore: filename=anykeystore-0.2-py3-none-any.whl size=16813 sha256=225fe9604ebab43cf5a59b913769e4da2dd1214aa171b91d898619739e2b35f9\n  Stored in directory: /root/.cache/pip/wheels/ce/9e/24/35542b7d376b53a6f8426524cc5a3f7998f975037b32d19906\n  Building wheel for pbkdf2 (setup.py) ... \u001b[?25ldone\n\u001b[?25h  Created wheel for pbkdf2: filename=pbkdf2-1.3-py3-none-any.whl size=5082 sha256=1f7b014ede084124d7ebe0491d4a919edcce92dc4a27dcebdd926aed46370d06\n  Stored in directory: /root/.cache/pip/wheels/f6/7d/8b/4269ff90fda80497ec59f6ff7d1e1596cb697c1dc8e9bbe320\nSuccessfully built apex velruse cryptacular anykeystore pbkdf2\nInstalling collected packages: translationstring, pbkdf2, anykeystore, zope.interface, zope.deprecation, wtforms, webob, venusian, rouge, python3-openid, plaster, PasteDeploy, hupper, cryptacular, wtforms-recaptcha, transaction, plaster-pastedeploy, zope.sqlalchemy, repoze.sendmail, pyramid, velruse, pyramid_mailer, apex\nSuccessfully installed PasteDeploy-3.1.0 anykeystore-0.2 apex-0.9.10.dev0 cryptacular-1.6.2 hupper-1.12.1 pbkdf2-1.3 plaster-1.1.2 plaster-pastedeploy-1.0.1 pyramid-2.0.2 pyramid_mailer-0.15.1 python3-openid-3.2.0 repoze.sendmail-4.4.1 rouge-1.0.1 transaction-4.0 translationstring-1.4 velruse-1.1.1 venusian-3.1.0 webob-1.8.7 wtforms-3.1.2 wtforms-recaptcha-0.3.2 zope.deprecation-5.0 zope.interface-6.1 zope.sqlalchemy-3.1\n","output_type":"stream"}]},{"cell_type":"code","source":"!python run_genmc.py --epoch_num 1 --model_path t5-base --choice_num 5 --data_path_train ./data/obqa/train.jsonl --data_path_dev ./data/obqa/dev.jsonl --data_path_test ./data/obqa/test.jsonl ","metadata":{"execution":{"iopub.status.busy":"2024-02-11T17:07:06.675330Z","iopub.execute_input":"2024-02-11T17:07:06.675754Z","iopub.status.idle":"2024-02-11T17:13:51.857618Z","shell.execute_reply.started":"2024-02-11T17:07:06.675709Z","shell.execute_reply":"2024-02-11T17:13:51.856487Z"},"trusted":true},"execution_count":8,"outputs":[{"name":"stdout","text":"Better speed can be achieved with apex installed from https://www.github.com/nvidia/apex.\n{\n  \"lr\": 0.0001,\n  \"model\": \"t5-base\",\n  \"seed\": 1,\n  \"bs\": 8,\n  \"gradient_accumulation_steps\": 1,\n  \"epoch\": 1,\n  \"train_path\": \"./data/obqa/train.jsonl\",\n  \"dev_path\": \"./data/obqa/dev.jsonl\",\n  \"test_path\": \"./data/obqa/test.jsonl\",\n  \"train_size\": 4957,\n  \"dev_size\": 500,\n  \"test_size\": 500,\n  \"num_hidden_layers\": 1,\n  \"external_sent_num\": null,\n  \"alpha\": 0.5,\n  \"beta\": 1\n}\nspiece.model: 100%|██████████████████████████| 792k/792k [00:00<00:00, 12.0MB/s]\ntokenizer.json: 100%|██████████████████████| 1.39M/1.39M [00:00<00:00, 36.0MB/s]\nconfig.json: 100%|█████████████████████████| 1.21k/1.21k [00:00<00:00, 6.23MB/s]\n/opt/conda/lib/python3.10/site-packages/transformers/models/t5/tokenization_t5.py:240: FutureWarning: This tokenizer was incorrectly instantiated with a model max length of 512 which will be corrected in Transformers v5.\nFor now, this behavior is kept to avoid breaking backwards compatibility when padding/encoding with `truncation is True`.\n- Be aware that you SHOULD NOT rely on t5-base automatically truncating your input to 512 when padding/encoding.\n- If you want to encode/pad to sequences longer than 512 you can either instantiate this tokenizer with `model_max_length` or pass `max_length` when encoding/padding.\n- To avoid this warning, please instantiate this tokenizer with `model_max_length` set to your preferred value.\n  warnings.warn(\nYou are using the default legacy behaviour of the <class 'transformers.models.t5.tokenization_t5.T5Tokenizer'>. This is expected, and simply means that the `legacy` (previous) behavior will be used so nothing changes for you. If you want to use the new behaviour, set `legacy=False`. This should only be set if you understand what it means, and thoroughly read the reason why this was added as explained in https://github.com/huggingface/transformers/pull/24565\nSpecial tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\nmodel.safetensors: 100%|█████████████████████| 892M/892M [00:10<00:00, 88.3MB/s]\ngeneration_config.json: 100%|███████████████████| 147/147 [00:00<00:00, 731kB/s]\n/opt/conda/lib/python3.10/site-packages/transformers/models/t5/modeling_t5.py:1584: FutureWarning: `T5ForConditionalGeneration.parallelize` is deprecated and will be removed in v5 of Transformers, you should load your model with `device_map='balanced'` in the call to `from_pretrained`. You can also provide your own `device_map` but it needs to be a dictionary module_name to device, so for instance {'encoder.block.0': 0, 'encoder.block.1': 1, ...}\n  warnings.warn(\n/opt/conda/lib/python3.10/site-packages/transformers/models/t5/modeling_t5.py:925: FutureWarning: `T5Stack.parallelize` is deprecated and will be removed in v5 of Transformers, you should load your model with `device_map='balanced'` in the call to `from_pretrained`. You can also provide your own `device_map` but it needs to be a dictionary module_name to device, so for instance {'block.0': 0, 'block.1': 1, ...}\n  warnings.warn(\n  0%|                                                    | 0/63 [00:00<?, ?it/s]/opt/conda/lib/python3.10/site-packages/transformers/generation/utils.py:1128: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n  warnings.warn(\n100%|███████████████████████████████████████████| 63/63 [00:28<00:00,  2.24it/s]\nbest_dev_acc: 0.188\n100%|███████████████████| 620/620 [05:14<00:00,  1.97it/s,  Epoch:0 loss:4.5997]\n100%|███████████████████████████████████████████| 63/63 [00:17<00:00,  3.56it/s]\ndev_acc: 0.538\n100%|███████████████████████████████████████████| 63/63 [00:17<00:00,  3.65it/s]\nnew best dev acc: 0.538 test_acc: 0.544 rouge: 0.36368039406500774\nbest dev acc: 0.538 best_test_acc: 0.544 best_dev_rouge_score: 0.36368039406500774 best_test_rouge_score: 0.3583547819345099\n","output_type":"stream"}]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}